{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Michigan Imputation Server","text":"<p>Michigan Imputation Server provides a free genotype imputation service using Minimac4. You can upload phased or unphased GWAS genotypes and receive phased and imputed genomes in return. Our server offers imputation from 1000 Genomes (Phase 1 and 3), CAAPA, HRC and the TOPMed reference panel. For all uploaded datasets an extensive QC is performed.</p> <p></p> <p>Please cite this paper if you use Michigan Imputation Server in your publication:</p> <p>Das S, Forer L, Sch\u00f6nherr S, Sidore C, Locke AE, Kwong A, Vrieze S, Chew EY, Levy S, McGue M, Schlessinger D, Stambolian D, Loh PR, Iacono WG, Swaroop A, Scott LJ, Cucca F, Kronenberg F, Boehnke M, Abecasis GR, Fuchsberger C. Next-generation genotype imputation service and methods. Nature Genetics 48, 1284\u20131287 (2016).</p> <p>The complete source code is hosted on GitHub using Travis CI for continuous integration.</p>"},{"location":"api/","title":"API Reference","text":"<p>The REST APIs provide programmatic ways to submit new jobs and to download data from Michigan Imputation Server. It identifies users using authentication tokens, responses are provided in JSON format.</p>"},{"location":"api/#authentication","title":"Authentication","text":"<p>Michigan Imputation Server uses a token-based authentication. The token is required for all future interaction with the server. The token can be created and downloaded from your user profile (username -&gt; Profile):</p> <p></p> <p>For security reasons, Api Tokens are valid for 30 days. You can check the status in the web interface.</p>"},{"location":"api/#job-submission-for-whole-genome-imputation","title":"Job Submission for Whole Genome Imputation","text":"<p>The API allows to submit imputation jobs and to set several parameters. For HLA imputation, please see below. </p>"},{"location":"api/#post-jobssubmitminimac4","title":"POST /jobs/submit/minimac4","text":"<p>The following parameters can be set:</p> Parameter Values Default Value Required files /path/to/file x mode <code>qconly</code> <code>phasing</code> <code>imputation</code> <code>imputation</code> password user-defined password auto generated and send by mail refpanel <code>hrc-r1.1</code> <code>1000g-phase-3-v5</code> <code>gasp-v2</code> <code>genome-asia-panel</code> <code>1000g-phase-1</code> <code>cappa</code> <code>hapmap-2</code> - x phasing <code>eagle</code> <code>no_phasing</code> <code>eagle</code> population <code>eur</code> <code>afr</code> <code>asn</code> <code>amr</code> <code>sas</code> <code>eas</code> <code>AA</code> <code>mixed</code> <code>all</code> - x build <code>hg19</code> <code>hg38</code> <code>hg19</code> r2Filter <code>0</code> <code>0.001</code> <code>0.1</code> <code>0.2</code> <code>0.3</code> <code>0</code>"},{"location":"api/#job-submission-for-hla-imputation","title":"Job Submission for HLA Imputation","text":"<p>The API also allows to submit imputation jobs using the HLA application. Please note, that the population parameter can be skipped here. </p>"},{"location":"api/#post-jobssubmitimputationserver-hla","title":"POST /jobs/submit/imputationserver-hla","text":"<p>The following parameters can be set:</p> Parameter Values Default Value Required files /path/to/file x mode <code>qconly</code> <code>phasing</code> <code>imputation</code> <code>imputation</code> password user-defined password auto generated and send by mail refpanel <code>multiethnic-hla-panel-Ggroup</code> <code>multiethnic-hla-panel-4digit</code> - x phasing <code>eagle</code> <code>no_phasing</code> <code>eagle</code> build <code>hg19</code> <code>hg38</code> <code>hg19</code> r2Filter <code>0</code> <code>0.001</code> <code>0.1</code> <code>0.2</code> <code>0.3</code> <code>0</code>"},{"location":"api/#examples-curl","title":"Examples: curl","text":""},{"location":"api/#submit-a-single-file","title":"Submit a single file","text":"<p>To submit a job please change <code>/path-to/file.vcf.gz</code> to a valid vcf file and update <code>TOKEN</code> with your API Token:</p> <p>Command:</p> <pre><code>TOKEN=\"YOUR-API-TOKEN\";\n\ncurl https://imputationserver.sph.umich.edu/api/v2/jobs/submit/minimac4 \\\n  -H \"X-Auth-Token: $TOKEN\" \\\n  -F \"files=@/path-to/file.vcf.gz\" \\\n  -F \"refpanel=1000g-phase-3-v5\" \\\n  -F \"population=eur\"\n</code></pre> <p>Response:</p> <pre><code>{\n  \"id\":\"job-20160504-161420\",\n  \"message\":\"Your job was successfully added to the job queue.\",\n  \"success\":true\n}\n</code></pre>"},{"location":"api/#submit-multiple-files","title":"Submit multiple files","text":"<p>Submits multiple vcf files and impute against 1000 Genomes Phase 3 reference panel.</p> <p>Command:</p> <pre><code>TOKEN=\"YOUR-API-TOKEN\";\n\ncurl https://imputationserver.sph.umich.edu/api/v2/jobs/submit/minimac4 \\\n  -H \"X-Auth-Token: $TOKEN\" \\\n  -F \"files=@/path-to/file1.vcf.gz\" \\\n  -F \"files=@/path-to/file2.vcf.gz\" \\\n  -F \"refpanel=1000g-phase-3-v5\" \\\n  -F \"population=eur\"\n</code></pre> <p>Response:</p> <pre><code>{\n  \"id\":\"job-20120504-155023\",\n  \"message\":\"Your job was successfully added to the job queue.\",\n  \"success\":true\n}\n</code></pre>"},{"location":"api/#submit-file-from-a-https","title":"Submit file from a HTTP(S)","text":"<p>Submits files from https with HRC reference panel and quality control.</p> <p>Command:</p> <pre><code>TOKEN=\"YOUR-API-TOKEN\";\n\ncurl  https://imputationserver.sph.umich.edu/api/v2/jobs/submit/minimac4 \\\n  -H \"X-Auth-Token: $TOKEN\" \\\n  -F \"files=https://imputationserver.sph.umich.edu/static/downloads/hapmap300.chr1.recode.vcf.gz\" \\\n  -F \"files-source=http\" \\\n  -F \"refpanel=hrc-r1.1\" \\\n  -F \"population=eur\" \\\n  -F \"mode=qconly\"\n</code></pre> <p>Response:</p> <pre><code>{\n  \"id\":\"job-20120504-155023\",\n  \"message\":\"Your job was successfully added to the job queue.\",\n  \"success\":true\n}\n</code></pre>"},{"location":"api/#examples-python","title":"Examples: Python","text":""},{"location":"api/#submit-single-vcf-file","title":"Submit single vcf file","text":"<pre><code>import requests\nimport json\n\n# imputation server url\nurl = 'https://imputationserver.sph.umich.edu/api/v2'\ntoken = 'YOUR-API-TOKEN';\n\n# add token to header (see Authentication)\nheaders = {'X-Auth-Token' : token }\ndata = {\n  'refpanel': '1000g-phase-3-v5',\n  'population': 'eur'\n}\n\n# submit new job\nvcf = '/path/to/genome.vcf.gz';\nfiles = {'files' : open(vcf, 'rb')}\nr = requests.post(url + \"/jobs/submit/minimac4\", files=files, data=data, headers=headers)\nif r.status_code != 200:\n  print(r.json()['message'])\n  raise Exception('POST /jobs/submit/minimac4 {}'.format(r.status_code))\n\n# print response and job id\nprint(r.json()['message'])\nprint(r.json()['id'])\n</code></pre>"},{"location":"api/#submit-multiple-vcf-files","title":"Submit multiple vcf files","text":"<pre><code>import requests\nimport json\n\n# imputation server url\nurl = 'https://imputationserver.sph.umich.edu/api/v2'\ntoken = 'YOUR-API-TOKEN';\n\n# add token to header (see Authentication)\nheaders = {'X-Auth-Token' : token }\ndata = {\n  'refpanel': '1000g-phase-3-v5',\n  'population': 'eur'\n}\n\n# submit new job\nvcf = '/path/to/file1.vcf.gz';\nvcf1 = '/path/to/file2.vcf.gz';\nfiles = [('files', open(vcf, 'rb')), ('files', open(vcf1, 'rb'))]\nr = requests.post(url + \"/jobs/submit/minimac4\", files=files, data=data, headers=headers)\nif r.status_code != 200:\n  print(r.json()['message'])\n  raise Exception('POST /jobs/submit/minimac4 {}'.format(r.status_code))\n\n# print message\nprint(r.json()['message'])\nprint(r.json()['id'])\n</code></pre>"},{"location":"api/#list-all-jobs","title":"List all jobs","text":"<p>All running jobs can be returned as JSON objects at once.</p>"},{"location":"api/#get-jobs","title":"GET /jobs","text":""},{"location":"api/#examples-curl_1","title":"Examples: curl","text":"<p>Command:</p> <pre><code>TOKEN=\"YOUR-API-TOKEN\";\n\ncurl -H \"X-Auth-Token: $TOKEN\" https://imputationserver.sph.umich.edu/api/v2/jobs\n</code></pre> <p>Response:</p> <pre><code>[\n  {\n    \"applicationId\":\"minimac\",\n    \"executionTime\":0,\n    \"id\":\"job-20160504-155023\",\n    \"name\":\"job-20160504-155023\",\n    \"positionInQueue\":0,\n    \"running\":false,\n    \"state\":5\n  },{\n    \"applicationId\":\"minimac\",\n    \"executionTime\":0,\n    \"id\":\"job-20160420-145809\",\n    \"name\":\"job-20160420-145809\",\n    \"positionInQueue\":0,\n    \"running\":false,\n    \"state\":5\n  },{\n    \"applicationId\":\"minimac\",\n    \"executionTime\":0,\n    \"id\":\"job-20160420-145756\",\n    \"name\":\"job-20160420-145756\",\n    \"positionInQueue\":0,\n    \"running\":false,\n    \"state\":5\n  }\n]\n</code></pre>"},{"location":"api/#example-python","title":"Example: Python","text":"<pre><code>import requests\nimport json\n\n# imputation server url\nurl = 'https://imputationserver.sph.umich.edu/api/v2'\ntoken = 'YOUR-API-TOKEN';\n\n# add token to header (see authentication)\nheaders = {'X-Auth-Token' : token }\n\n# get all jobs\nr = requests.get(url + \"/jobs\", headers=headers)\nif r.status_code != 200:\n    raise Exception('GET /jobs/ {}'.format(r.status_code))\n\n# print all jobs\nfor job in r.json():\n    print('{} [{}]'.format(job['id'], job['state']))\n</code></pre>"},{"location":"api/#monitor-job-status","title":"Monitor Job Status","text":""},{"location":"api/#jobsidstatus","title":"/jobs/{id}/status","text":""},{"location":"api/#example-curl","title":"Example: curl","text":"<p>Command:</p> <pre><code>TOKEN=\"YOUR-API-TOKEN\";\n\ncurl -H \"X-Auth-Token: $TOKEN\" https://imputationserver.sph.umich.edu/api/v2/jobs/job-20160504-155023/status\n</code></pre> <p>Response:</p> <pre><code>{\n  \"application\":\"Michigan Imputation Server (Minimac4) 1.5.8\",\n  \"applicationId\":\"minimac4\",\n  \"deletedOn\":-1,\n  \"endTime\":1462369824173,\n  \"executionTime\":0,\n  \"id\":\"job-20160504-155023\",\n  \"logs\":\"\",\n  \"name\":\"job-20160504-155023\",\n  \"outputParams\":[],\n  \"positionInQueue\":0,\n  \"running\":false,\n  \"startTime\":1462369824173,\n  \"state\":5\n  ,\"steps\":[]\n}\n</code></pre>"},{"location":"api/#monitor-job-details","title":"Monitor Job Details","text":""},{"location":"api/#jobsid","title":"/jobs/{id}","text":""},{"location":"api/#example-curl_1","title":"Example: curl","text":"<pre><code>TOKEN=\"YOUR-API-TOKEN\";\n\ncurl -H \"X-Auth-Token: $TOKEN\" https://imputationserver.sph.umich.edu/api/v2/jobs/job-20160504-155023/\n</code></pre>"},{"location":"contact/","title":"Contact","text":"<p>The complete Imputation Server 2 source code is available on GitHub and has been developed by Lukas Forer and Sebastian Sch\u00f6nherr from the Institute of Genetic Epidemiology, Medical University of Innsbruck. </p> <p>Feel free to create issues and pull requests. Before contacting us, please have a look at the FAQ page first. </p>"},{"location":"contact/#michigan-imputation-server-team","title":"Michigan Imputation Server Team","text":"<p>Michigan Imputation Server provides a free genotype imputation service using Minimac4. You can upload phased or unphased GWAS genotypes and receive phased and imputed genomes in return. For all uploaded data sets an extensive QC is performed.</p> <ul> <li>Christian Fuchsberger</li> <li>Lukas Forer</li> <li>Sebastian Sch\u00f6nherr</li> <li>Sayantan Das</li> <li>Gon\u00e7alo Abecasis</li> </ul> <p>Please contact Christian Fuchsberger in case of other problems.</p>"},{"location":"contact/#topmed-imputation-server-team","title":"TOPMed Imputation Server Team","text":"<p>Michigan Imputation Server provides a free genotype imputation service using Minimac4. You can upload phased or unphased GWAS genotypes and receive phased and imputed genomes in return. For all uploaded data sets an extensive QC is performed.</p> <ul> <li>Albert Smith</li> <li>Andy Boughton</li> </ul> <p>Please use this addrees for all inquiries.</p>"},{"location":"contact/#imputation-engine-minimac4","title":"Imputation engine: Minimac4","text":"<p>Minimac4 is a lower memory and more computationally efficient implementation of the genotype imputation algorithms in minimac/mininac2/minimac3.</p> <ul> <li>Sayantan Das</li> <li>Christian Fuchsberger</li> <li>Gon\u00e7alo Abecasis</li> </ul>"},{"location":"contact/#cloud-framework-cloudgene","title":"Cloud framework: Cloudgene","text":"<p>Cloudgene is a framework to build Software As A Service (SaaS) platforms for data analysis pipelines. By connecting command-line programs, scripts or Hadoop applications to Cloudgene, a powerful web application can be created within minutes. Cloudgene supports the complete workflow including data transfer, program execution and data export. Cloudgene is developed at the Division of Genetic Epidemiology Innsbruck in cooperation with the Center for Statistical Genetics, University of Michigan.</p> <ul> <li>Lukas Forer</li> <li>Sebastian Sch\u00f6nherr</li> </ul>"},{"location":"contact/#phasing-engine-eagle2","title":"Phasing engine: Eagle2","text":"<p>For haplotype phasing Eagle2 is used. Eagle2 attains high accuracy across a broad range of cohort sizes by efficiently leveraging information from large external reference panels (such as the Haplotype Reference Consortium; HRC).</p>"},{"location":"create-reference-panels/","title":"Create a Reference Panel","text":"<p>This tutorial will help you to create your own reference panel and integrate it into Michigan Imputation Server. </p>"},{"location":"create-reference-panels/#required-software","title":"Required Software","text":"<ul> <li>To create the m3vcf files for imputation, please use Minimac3.</li> <li>To create the bcf files for phasing, please use bcftools and tabix.</li> <li>To create the legend files for QC, please use vcftools or bcftools.</li> </ul>"},{"location":"create-reference-panels/#folder-structure","title":"Folder Structure","text":"<p>We recommend the following folder structure:</p> <pre><code>my-ref-panel\n\u251c\u2500\u2500 cloudgene.yaml\n\u251c\u2500\u2500 bcfs\n|   \u251c\u2500\u2500 chr1.bcf\n    \u251c\u2500\u2500 chr1.bcf.csi\n|   \u251c\u2500\u2500 ...\n    \u251c\u2500\u2500 chr22.bcf\n|   \u2514\u2500\u2500 chr22.bcf.csi\n\u251c\u2500\u2500 legends\n|   \u251c\u2500\u2500 chr1.legend.gz\n|   \u251c\u2500\u2500 ...\n|   \u2514\u2500\u2500 chr22.legend.gz\n\u251c\u2500\u2500 m3vcfs\n|   \u251c\u2500\u2500 chr1.m3vcf.gz\n|   \u251c\u2500\u2500 ...\n|   \u2514\u2500\u2500 chr22.m3vcf.gz\n\u251c\u2500\u2500 map\n|   \u2514\u2500\u2500 genetic_map_hg19_withX.txt.gz\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"create-reference-panels/#init-build-grch37hg19","title":"Init (build GRCh37/hg19)","text":"<p>Create a new folder and add a <code>cloudgene.yaml</code> file. </p> <pre><code>name:  My Reference Panel name\nid: unique-id\ndescription: a short description\ncategory: RefPanel\nversion: 1.0.0\nwebsite: http://my-reference-panel.com\n\nproperties:\n  hdfs: ${hdfs_app_folder}/m3vcfs/chr$chr.m3vcf.gz\n  legend: ${local_app_folder}/legends/chr$chr.legend.gz\n  mapEagle: ${hdfs_app_folder}/map/genetic_map_hg19_withX.txt.gz\n  refEagle: ${hdfs_app_folder}/bcfs/chr$chr.bcf\n  build: hg19\n  samples:\n    all: 2504\n    mixed: -1\n  populations:\n    all: ALL\n    mixed: Other/Mixed\n\ninstallation:\n\n  - import:\n      source: ${local_app_folder}/bcfs\n      target: ${hdfs_app_folder}/bcfs\n\n  - import:\n      source: ${local_app_folder}/m3vcfs\n      target: ${hdfs_app_folder}/m3vcfs\n\n  - import:\n      source: ${local_app_folder}/map\n      target: ${hdfs_app_folder}/map\n</code></pre>"},{"location":"create-reference-panels/#adaptions-for-build-grch38hg38","title":"Adaptions for build GRCh38/hg38","text":"<p>For a reference panel build 38, the following options must be added to <code>properties</code> in the <code>cloudgene.yaml</code> file: <pre><code>    mapMinimac: ${app_hdfs_folder}/map/geneticMapFile.b38.map.txt   \n    mapEagle: ${app_hdfs_folder}/map/genetic_map_hg38_withX.txt.gz\n    build: hg38\n</code></pre></p>"},{"location":"create-reference-panels/#prepare-vcf-files","title":"Prepare VCF files","text":"<p>Michigan Imputaiton Server requires each chromosome in a seperated file. Chromosome X must be split into three parts: chrX.PAR1, chrX.PAR2 and chrX.nonPAR. Use bcftools to split by region:</p> <p><code>bcftools view &lt;vcf-input&gt; -r &lt;region&gt; -o &lt;vcf-out&gt; -O z</code></p>"},{"location":"create-reference-panels/#chromosome-x-regions-grch37hg19","title":"Chromosome X regions GRCh37/hg19","text":"<p>Use the following regions for the <code>-r</code> option:</p> <pre><code>X:60001-2699520 (chrX.PAR1)\nX:2699521-154931043 (chrX.nonPAR)\nX:154931044-155260560 (chrX.PAR2)\n</code></pre>"},{"location":"create-reference-panels/#chromosome-x-regions-grch38hg38","title":"Chromosome X regions GRCh38/hg38","text":"<pre><code>chrX:10001-2781479 (chrX.PAR1)\nchrX:2781480-155701382 (chrX.nonPAR)\nchrX:155701383-156030895 (chrX.PAR2)\n</code></pre>"},{"location":"create-reference-panels/#create-bcf-files","title":"Create bcf files","text":"<p>BCF files are required for phasing with eagle.</p> <pre><code>for chr in `seq 1 22` X.nonPAR X.PAR1 X.PAR2\ndo\n    bcftools view chr${chr}.vcf.gz -O b -o chr${chr}.bcf\n    bcftools index chr${chr}.bcf\ndone\n</code></pre>"},{"location":"create-reference-panels/#create-m3vcf-files","title":"Create m3vcf files","text":"<p>m3vcf files are used to store large reference panels in a compact way. Learn more about the file format here. For GRCh38/hg38, <code>--mychromosome</code> must be added, since chromosomes are coded as <code>chr1</code> - <code>chr22</code>.  </p> <pre><code>for chr in `seq 1 22` X.nonPAR X.PAR1 X.PAR2\ndo\n    Minimac3 --refHaps chr${chr}.vcf.gz --processReference --prefix m3vcfs/chr${chr} --rsid\ndone\n</code></pre>"},{"location":"create-reference-panels/#create-legend-files","title":"Create legend files","text":"<p>A legend file is a tab-delimited file consisting of 5 columns (<code>id</code>, <code>position</code>, <code>a0</code>, <code>a1</code>, <code>all.aaf</code>).</p> <p><pre><code>echo \"id position a0 a1 all.aaf\" &gt; header\n    for chr in `seq 1 22` X\n    do\n    bcftools query -f '%CHROM %POS %REF %ALT %AC %AN\\n' chr${chr}.bcf |  awk -F\" \" 'BEGIN { OFS = \" \" } {print $1\":\"$2 \" \" $2 \" \" $3 \" \"$4  \" \"  $5/$6}' | cat header - | bgzip &gt; chr${chr}.legend.gz \ndone\n</code></pre> or in case AC / AN is not defined:</p> <pre><code>echo \"id position a0 a1 all.aaf\" &gt; header\nfor chr in `seq 1 22`\ndo\n    vcftools --gzvcf chr${chr}.vcf.gz --freq --out chr${chr}\n    sed 's/:/\\t/g' chr${chr}.frq | sed 1d | awk '{print $1\":\"$2\" \"$2\" \"$5\" \"$7\" \"$8}' &gt; chr${chr}.legend\n    cat header chr${chr}.legend | bgzip &gt; chr${chr}.legend.gz\n    rm chr${chr}.legend\ndone\n</code></pre>"},{"location":"create-reference-panels/#reference-genetic-maps","title":"Reference genetic maps","text":"<p>The genetic maps for eagle (hg19/hg38) can be found here.</p>"},{"location":"create-reference-panels/#integrate-your-new-reference-panel","title":"Integrate your new reference panel","text":"<p>The created folder structure must be compressed to a zip archive and can now be integrated into Michigan Imputation Server. Please see here to start a Docker container and integrate the panel. A full working zip archive for Hapmap can be found here.</p>"},{"location":"data-sensitivity/","title":"Data Security","text":"<p>Since data is transfered to our server located in Michigan, a wide array of security measures are in force:</p> <ul> <li>The complete interaction with the server is secured with HTTPS.</li> <li>Input data is deleted from our servers as soon it is not needed anymore.</li> <li>We only store the number of samples and markers analyzed, we don't ever \"look\" at your data in anyway.</li> <li>All results are encrypted with a strong one-time password - thus, only you can read them.</li> <li>After imputation is finished, the data uploader has 7 days to use an encrypted connection to get results back.</li> <li>The complete source code is available in a public Github repository.</li> </ul>"},{"location":"data-sensitivity/#who-has-access","title":"Who has access?","text":"<p>To upload and download data, users must register with a unique e-mail address and strong password. Each user can only download imputation results for samples that they have themselves uploaded; no other imputation server users will be able to access your data.</p>"},{"location":"data-sensitivity/#cookies","title":"Cookies","text":"<p>We value your privacy and are committed to transparency regarding the use of cookies on our website. Below, we outline our cookie policy to provide you with clarity and assurance.</p>"},{"location":"data-sensitivity/#what-are-cookies","title":"What are cookies?","text":"<p>Cookies are small text files that are placed on your device when you visit a website. They serve various purposes, including enhancing user experience, facilitating website functionality, and analyzing website traffic.</p>"},{"location":"data-sensitivity/#how-do-we-use-cookies","title":"How do we use cookies?","text":"<p>We use cookies only for the purpose of facilitating login functionality. These cookies help us recognize your device and authenticate your access to our platform securely. We do not track any personal information or analyze user activities through cookies.</p>"},{"location":"data-sensitivity/#why-do-we-use-cookies","title":"Why do we use cookies?","text":"<p>Cookies are essential for providing seamless login experiences to our users. By storing authentication information, cookies enable you to access your account efficiently without the need for repetitive login procedures. We respect your privacy and limit cookie usage exclusively to login purposes.</p>"},{"location":"data-sensitivity/#what-security-or-firewalls-protect-access","title":"What security or firewalls protect access?","text":"<p>A wide array of security measures are in force on the imputation servers:</p> <ul> <li>SSH login to the servers is restricted to only systems administrators.</li> <li>Direct root login via SSH is not allowed from the public Internet.</li> <li>The public-facing side of the servers sits behind the School of Public Health's Checkpoint virtual firewall instance where a default-deny policy is used on inbound traffic; only explicitly allowed TCP ports are passed.</li> <li>The School of Public Health also makes use of NIDS technologies such as Snort and Peakflow on its network links for traffic analysis and threat detection.</li> <li>On imputation server itself, updates are run regularly by systems administrators who follow several zero-day computer security announcement lists; the OSSEC HIDS is used for log analysis and anomaly detection; and Denyhosts is used to thwart brute-force SSH login attacks.</li> </ul>"},{"location":"data-sensitivity/#what-encryption-of-the-data-is-used-while-the-data-are-present","title":"What encryption of the data is used while the data are present?","text":"<p>Imputation results are encrypted with a one-time password generated by the system. The password consists of lower characters, upper characters, special characters and numbers with max. 3 duplicates.</p>"},{"location":"docker/","title":"Michigan Imputation Server on Docker","text":"<p>A docker image and instructions are available here.</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":""},{"location":"faq/#i-did-not-receive-a-password-for-my-imputation-job","title":"I did not receive a password for my imputation job","text":"<p>Michigan Imputation Server creates a random password for each imputation job. This password is not stored on server-side at any time. If you didn't receive a password, please check your Mail SPAM folder. Please note that we are not able to re-send you the password.  </p>"},{"location":"faq/#unzip-command-is-not-working","title":"Unzip command is not working","text":"<p>Please check the following points: (1) When selecting AES256 encryption, please use 7z to unzip your files (Debian: <code>sudo apt-get install p7zip-full</code>). For our default encryption all common programs should work. (2) If your password includes special characters (e.g. \\), please put single or double quotes around the password when extracting it from the command line (e.g. <code>7z x -p\"PASSWORD\" chr_22.zip</code>).</p>"},{"location":"faq/#extending-expiration-date-or-reset-download-counter","title":"Extending expiration date or reset download counter","text":"<p>Your data is available for 7 days. In case you need an extension, please let us know.</p>"},{"location":"faq/#how-can-i-improve-the-download-speed","title":"How can I improve the download speed?","text":"<p>aria2 tries to utilize your maximum download bandwidth. Please keep in mind to raise the k parameter significantly (-k, --min-split-size=SIZE). You will otherwise hit the Michigan Imputation Server download limit for each file (thanks to Anthony Marcketta for point this out).</p>"},{"location":"faq/#can-i-download-all-results-at-once","title":"Can I download all results at once?","text":"<p>We provide wget command for all results. Please open the results tab. The last column in each row includes direct links to all files.</p>"},{"location":"faq/#can-i-set-up-michigan-imputation-server-locally","title":"Can I set up Michigan Imputation Server locally?","text":"<p>We are providing a single-node Docker image that can be used to impute from Hapmap2 and 1000G Phase3 locally. Click here to give it a try. For usage in production, we highly recommend setting up a Hadoop cluster.</p>"},{"location":"faq/#your-web-service-looks-great-can-i-set-up-my-own-web-service-as-well","title":"Your web service looks great. Can I set up my own web service as well?","text":"<p>All web service functionality is provided by Cloudgene. Please contact us, in case you want to set up your own service.</p>"},{"location":"getting-started/","title":"Getting started","text":"<p>To use Michigan Imputation Server, a registration is required. We send an activation mail to the provided address. Please follow the instructions in the email to activate your account. If it doesn't arrive, ensure you have entered the correct email address and check your spam folder.</p> <p>After the email address has been verified, the service can be used without any costs.</p> <p>Please cite this paper if you use Michigan Imputation Server in your GWAS study:</p> <p>Das S, Forer L, Sch\u00f6nherr S, Sidore C, Locke AE, Kwong A, Vrieze S, Chew EY, Levy S, McGue M, Schlessinger D, Stambolian D, Loh PR, Iacono WG, Swaroop A, Scott LJ, Cucca F, Kronenberg F, Boehnke M, Abecasis GR, Fuchsberger C. Next-generation genotype imputation service and methods. Nature Genetics 48, 1284\u20131287 (2016).</p>"},{"location":"getting-started/#setup-your-first-imputation-job","title":"Setup your first imputation job","text":"<p>Please login with your credentials and click on the Run tab to start a new imputation job. The submission dialog allows you to specify the properties of your imputation job.</p> <p></p> <p>The following options are available:</p>"},{"location":"getting-started/#reference-panel","title":"Reference Panel","text":"<p>Our server offers genotype imputation from different reference panels. The most accurate and largest panel is HRC (Version r1.1 2016). Please select one that fulfills your needs and supports the population of your input data:</p> <ul> <li>HRC (Version r1.1 2016)</li> <li>HLA Imputation Panel: two-field (four-digit) and G-group resolution</li> <li>HRC (Version r1 2015)</li> <li>1000 Genomes Phase 3 (Version 5)</li> <li>1000 Genomes Phase 1 (Version 3)</li> <li>CAAPA - African American Panel</li> <li>HapMap 2</li> </ul> <p>More details about all available reference panels can be found here.</p>"},{"location":"getting-started/#upload-vcf-files-from-your-computer","title":"Upload VCF files from your computer","text":"<p>When using the file upload, data is uploaded from your local file system to Michigan Imputation Server. By clicking on Select Files an open dialog appears where you can select your VCF files:</p> <p></p> <p>Multiple files can be selected using the <code>ctrl</code>, <code>cmd</code> or <code>shift</code> keys, depending on your operating system. After you have confirmed your choice, all selected files are listed in the submission dialog:</p> <p></p> <p>Please make sure that all files fulfill the requirements.</p> <p>Important</p> <p>Since version 1.7.2 URL-based uploads (sftp and http) are no longer supported. Please use direct file uploads instead. </p>"},{"location":"getting-started/#build","title":"Build","text":"<p>Please select the build of your data. Currently the options hg19 and hg38 are supported. Michigan Imputation Server automatically updates the genome positions (liftOver) of your data. All reference panels except TOPMed are based on hg19 coordinates.</p>"},{"location":"getting-started/#rsq-filter","title":"rsq Filter","text":"<p>To minimize the file size, Michigan Imputation Server includes a r<sup>2</sup> filter option, excluding all imputed SNPs with a r<sup>2</sup>-value (= imputation quality) smaller then the specified value.</p>"},{"location":"getting-started/#phasing","title":"Phasing","text":"<p>If your uploaded data is unphased, Eagle v2.4 will be used for phasing. In case your uploaded VCF file already contains phased genotypes, please select the \"No phasing\" option.</p> Algorithm Description Eagle v2.4 The Eagle algorithm estimates haplotype phase using the HRC reference panel. This method is also suitable for single sample imputation. After phasing or imputation you will receive phased genotypes in your VCF files."},{"location":"getting-started/#population","title":"Population","text":"<p>Please select the population of your uploaded samples. This information is used to compare the allele frequencies between your data and the reference panel. Please note that not every reference panel supports all sub-populations.</p> Population Supported Reference Panels AFR all AMR all EUR all Mixed all AA CAAPA ASN 1000 Genomes Phase 1 (Version 3) EAS 1000 Genomes Phase 3 (Version 5) SAS 1000 Genomes Phase 3 (Version 5) <p>In case your population is not listed or your samples are from different populations, please select Mixed to skip the allele frequency check. For mixed populations, no QC-Report will be created.</p>"},{"location":"getting-started/#mode","title":"Mode","text":"<p>Please select if you want to run Quality Control &amp; Imputation, Quality Control &amp; Phasing Only or Quality Control Only.</p>"},{"location":"getting-started/#aes-256-encryption","title":"AES 256 encryption","text":"<p>All Imputation Server results are encrypted by default. Please tick this checkbox if you want to use AES 256 encryption instead of the default encryption method. Please note that AES encryption does not work with standard unzip programs. We recommend to use 7z instead.</p>"},{"location":"getting-started/#start-your-imputation-job","title":"Start your imputation job","text":"<p>After confirming our Terms of Service, the imputation process can be started immediately by clicking on Start Imputation. Input Validation and Quality Control are executed immediately to give you feedback about the data-format and its quality. If your data passed this steps, your job is added to our imputation queue and will be processed as soon as possible. You can check the position in the queue on the job summary page.</p> <p></p> <p>We notify you by email as soon as the job is finished or your data don't pass the Quality Control steps.</p>"},{"location":"getting-started/#input-validation","title":"Input Validation","text":"<p>In a first step we check if your uploaded files are valid and we calculate some basic statistics such as amount of samples, chromosomes and SNPs.</p> <p></p> <p>After Input Validation has finished, basic statistics can be viewed directly in the web interface.</p> <p></p> <p>If you encounter problems with your data please read this tutorial about Data Preparation to ensure your data is in the correct format.</p>"},{"location":"getting-started/#quality-control","title":"Quality Control","text":"<p>In this step we check each variant and exclude it in case of:</p> <ol> <li>contains invalid alleles</li> <li>duplicates</li> <li>indels</li> <li>monomorphic sites</li> <li>allele mismatch between reference panel and uploaded data</li> <li>SNP call rate &lt; 90%</li> </ol> <p>All filtered variants are listed in a file called <code>statistics.txt</code> which can be downloaded by clicking on the provided link. More informations about our QC pipeline can be found here.</p> <p></p> <p>If you selected a population, we compare the allele frequencies of the uploaded data with those from the reference panel. The result of this check is available in the QC report and can be downloaded by clicking on <code>qcreport.html</code>.</p>"},{"location":"getting-started/#pre-phasing-and-imputation","title":"Pre-phasing and Imputation","text":"<p>Imputation is achieved with Minimac4. The progress of all uploaded chromosomes is updated in real time and visualized with different colors.</p> <p></p>"},{"location":"getting-started/#data-compression-and-encryption","title":"Data Compression and Encryption","text":"<p>If imputation was successful, we compress and encrypt your data and send you a random password via mail.</p> <p></p> <p>This password is not stored on our server at any time. Therefore, if you lost the password, there is no way to resend it to you.</p>"},{"location":"getting-started/#download-results","title":"Download results","text":"<p>The user is notified by email, as soon as the imputation job has finished. A zip archive including the results can be downloaded directly from the server. To decrypt the results, a one-time password is generated by the server and included in the email. The QC report and filter statistics can be displayed and downloaded as well.</p> <p></p> <p>All data is deleted automatically after 7 days</p> <p>Be sure to download all needed data in this time period. We send you a reminder 48 hours before we delete your data. Once your job hast the state retired, we are not able to recover your data!</p>"},{"location":"getting-started/#download-via-a-web-browser","title":"Download via a web browser","text":"<p>All results can be downloaded directly via your browser by clicking on the filename.</p> <p></p> <p>In order to download results via the commandline using <code>wget</code>or <code>aria2</code> you need to click on the share symbol (located right to the file size) to get the needed private links.</p> <p></p> <p>A new dialog appears which provides you the private link. Click on the tab wget command to get a copy &amp; paste ready command that can be used on Linux or MacOS to download the file in you terminal:</p>"},{"location":"getting-started/#download-all-results-at-once","title":"Download all results at once","text":"<p>To download all files of a folder (for example folder Imputation Results) you can click on the share symbol of the folder:</p> <p></p> <p>A new dialog appears which provides you all private links at once. Click on the tab wget commands to get copy &amp; paste ready commands that can be used on Linux or MacOS to download all files.</p>"},{"location":"pipeline/","title":"Pipeline Overview","text":"<p>Our pipeline performs the following steps:</p>"},{"location":"pipeline/#quality-control","title":"Quality Control","text":"<ul> <li>Create chunks with a size of 20 Mb</li> <li> <p>For each 20Mb chunk we perform the following checks:</p> <p>On Chunk level:</p> <ul> <li>Determine amount of valid variants: A variant is valid iff it is included in the reference panel. At least 3 variants must be included.</li> <li>Determine amount of variants found in the reference panel: At least 50 % of the variants must be be included in the reference panel.</li> <li>Determine sample call rate: At least 50 % of the variants must be called for each sample.  </li> </ul> <p>Chunk exclusion: if (#variants &lt; 3 || overlap &lt; 50% || sampleCallRate &lt; 50%)</p> <p>On Variant level:</p> <ul> <li>Check alleles: Only A,C,G,T are allowed</li> <li>Calculate alternative allele frequency (AF): Mark all with a AF &gt; 0.5.</li> <li>Calculate SNP call rate</li> <li>Calculate chi square for each variant (reference panel vs. study data)</li> <li>Determine allele switches: Compare ref and alt of reference panel with study data (A/T and C/G variants are ignored).</li> <li>Determine strand flips: After eliminating possible allele switches, flip and compare ref/alt from reference panel with study data.</li> <li>Determine allele switches in combination with strand flips: Combine the two rules from above.  </li> </ul> <p>Variant exclusion: Variants are excluded in case of: [a] invalid alleles occur (!(A,C,G,T)), [b] duplicates (DUP filter or (pos - 1 == pos)), [c] indels, [d] monomorphic sites, [e] allele mismatch between reference panel and study, [f] SNP call rate &lt; 90%.</p> <p>On Sample level:</p> <ul> <li>For chr1-22, a chunk is excluded if one sample has a call rate &lt; 50 %. Only complete chunks are excluded, not samples (see \"On Chunk level\" above)</li> </ul> </li> <li> <p>Perform a liftOver step, if build of input data and reference panel does not match (b37 vs b38).</p> </li> </ul>"},{"location":"pipeline/#phasing","title":"Phasing","text":"<ul> <li>Execute for each chunk one of the following phasing algorithms (we use an overlap of 5 Mb). For example, chr20:1-20000000 and reference population EUR:</li> </ul> <p>Eagle2 <pre><code>./eagle --vcfRef HRC.r1-1.GRCh37.chr20.shapeit3.mac5.aa.genotypes.bcf\n--vcfTarget chunk_20_0000000001_0020000000.vcf.gz  --geneticMapFile genetic_map_chr20_combined_b37.txt\n--outPrefix chunk_20_0000000001_0020000000.phased --bpStart 1 --bpEnd 25000000 --allowRefAltSwap\n--vcfOutFormat z\n</code></pre></p> <p>Please note: Target-only sites for unphased data are not included in the final output.</p>"},{"location":"pipeline/#imputation","title":"Imputation","text":""},{"location":"pipeline/#_1","title":"Pipeline Overview","text":"<ul> <li>Execute for each chunk minimac in order to impute the phased data (we use a window of 500 kb):</li> </ul> <p><pre><code>./Minimac4 --refHaps HRC.r1-1.GRCh37.chr1.shapeit3.mac5.aa.genotypes.m3vcf.gz\n--haps chunk_1_0000000001_0020000000.phased.vcf --start 1 --end 20000000\n--window 500000 --prefix chunk_1_0000000001_0020000000 --cpus 1 --chr 20 --noPhoneHome\n--format GT,DS,GP --allTypedSites --meta --minRatio 0.00001\n</code></pre> If a map file is available (currently TOPMed only), the following cmd is executed:</p> <pre><code>./Minimac4 --refHaps HRC.r1-1.GRCh38.chr1.shapeit3.mac5.aa.genotypes.m3vcf.gz\n--haps chunk_1_0000000001_0020000000.phased.vcf --start 1 --end 20000000\n--window 500000 --prefix chunk_1_0000000001_0020000000 --cpus 1 --chr 20 --noPhoneHome\n--format GT,DS,GP --allTypedSites --meta --minRatio 0.00001 --referenceEstimates --map B38_MAP_FILE.map\n</code></pre>"},{"location":"pipeline/#hla-imputation-pipeline","title":"HLA Imputation Pipeline","text":"<p>In addition to intergenic SNPs, HLA imputation outputs five different types of markers: (1) binary marker for classical HLA alleles; (2) binary marker for the presence/absence of a specific amino acid residue; (3) HLA intragenic SNPs, and (4) binary markers for insertion/deletions, as described in the typical output below. The goal is to minimize prior assumption on which types of variations will be causal and test all types of variations simultaneously in an unbiased fashion. However, the users are always free to restrict analyses to specific marker subsets.</p> <p>Note</p> <p>For binary encodings, A = Absent, T = Present.</p> Type Format Example Classical HLA alleles HLA_[GENE]*[ALLELE] HLA_A*01:02 (two-field allele)  HLA_A*02 (one-field allele) HLA amino acids AA_[GENE]_[AMINO ACID POSITION]_[GENOMIC POSITION]_[EXON]_[RESIDUE] AA_B_97_31324201_exon3_V (amino acid position 97 in HLA-B, genomic position 31324201 (GrCh37) in exon 3, residue = V (Val) ) HLA intragenic SNPs SNPS_[GENE]_[GENE POSITION]_[GENOMIC POSITION]_[EXON/INTRON] SNPS_C_2666_31237183_intron6 (SNP at position 2666 of the gene body, genomic position 31237183 in intron 6) Insertions/deletions INDEL_[TYPE]_[GENE]_[POSITION] INDEL_AA_C_300x301_31237792 Indel between amino acids 300 and 301 in HLA-C, at genomic position 31237792) <p>  We note that our current implementation of the reference panel is limited to the G-group resolution (DNA sequences that determine the exons 2 and 3 for class I and exon 2 for class II genes), and amino acid positions outside the binding groove were taken as its best approximation. When converting G-group alleles to the two-field resolution, we first approximated G-group alleles to their corresponding allele at the four-field resolution based on the ordered allele list in the distributed IPD-IMGT/HLA database (version 3.32.0). We explicitly include exonic information in the HLA-TAPAS output.</p> <p>For more information about HLA imputation and help, please visit https://github.com/immunogenomics/HLA-TAPAS.</p>"},{"location":"pipeline/#compression-and-encryption","title":"Compression and Encryption","text":"<ul> <li>Merge all chunks of one chromosome into one single vcf.gz</li> <li>Encrypt data with one-time password</li> </ul>"},{"location":"pipeline/#chromosome-x-pipeline","title":"Chromosome X Pipeline","text":"<p>Additionally to the standard QC, the following per-sample checks are executed for chrX:</p> <ul> <li>Ploidy Check: Verifies if all variants in the nonPAR region are either haploid or diploid.</li> <li>Mixed Genotypes Check: Verifies if the amount of mixed genotypes (e.g. 1/.) is &lt; 10 %.</li> </ul> <p>For phasing and imputation, chrX is split into three independent chunks (PAR1, nonPAR, PAR2). These splits are then automatically merged by Michigan Imputation Server and are returned as one complete chromosome X file. Only Eagle is supported.</p>"},{"location":"prepare-your-data/","title":"Data preparation","text":"<p>Michigan Imputation Server accepts VCF files compressed with bgzip. Please make sure the following requirements are met:</p> <ul> <li>Create a separate vcf.gz file for each chromosome.</li> <li>Variations must be sorted by genomic position.</li> <li>GRCh37 or GRCh38 coordinates are required.</li> </ul> <p>Note</p> <p>Several *.vcf.gz files can be uploaded at once.</p>"},{"location":"prepare-your-data/#quality-control-for-hrc-1000g-and-caapa-imputation","title":"Quality Control for HRC, 1000G and CAAPA imputation","text":"<p>Will Rayner provides a great toolbox to prepare data: HRC or 1000G Pre-imputation Checks.</p> <p>The main steps for HRC are:</p>"},{"location":"prepare-your-data/#download-tool-and-sites","title":"Download tool and sites","text":"<pre><code>wget http://www.well.ox.ac.uk/~wrayner/tools/HRC-1000G-check-bim-v4.2.7.zip\nwget ftp://ngs.sanger.ac.uk/production/hrc/HRC.r1-1/HRC.r1-1.GRCh37.wgs.mac5.sites.tab.gz\n</code></pre>"},{"location":"prepare-your-data/#convert-pedmap-to-bed","title":"Convert ped/map to bed","text":"<pre><code>plink --file &lt;input-file&gt; --make-bed --out &lt;output-file&gt;\n</code></pre>"},{"location":"prepare-your-data/#create-a-frequency-file","title":"Create a frequency file","text":"<pre><code>plink --freq --bfile &lt;input&gt; --out &lt;freq-file&gt;\n</code></pre>"},{"location":"prepare-your-data/#execute-script","title":"Execute script","text":"<pre><code>perl HRC-1000G-check-bim.pl -b &lt;bim file&gt; -f &lt;freq-file&gt; -r HRC.r1-1.GRCh37.wgs.mac5.sites.tab -h\nsh Run-plink.sh\n</code></pre>"},{"location":"prepare-your-data/#create-vcf-using-vcfcooker","title":"Create vcf using VcfCooker","text":"<pre><code>vcfCooker --in-bfile &lt;bim file&gt; --ref &lt;reference.fasta&gt;  --out &lt;output-vcf&gt; --write-vcf\nbgzip &lt;output-vcf&gt;\n</code></pre>"},{"location":"prepare-your-data/#additional-tools","title":"Additional Tools","text":""},{"location":"prepare-your-data/#convert-pedmap-files-to-vcf-files","title":"Convert ped/map files to VCF files","text":"<p>Several tools are available:  plink2,  BCFtools or VcfCooker.  </p> <pre><code>plink --ped study_chr1.ped --map study_chr1.map --recode vcf --out study_chr1\n</code></pre> <p>Create a sorted vcf.gz file using BCFtools:</p> <pre><code>bcftools sort study_chr1.vcf -Oz -o study_chr1.vcf.gz\n</code></pre>"},{"location":"prepare-your-data/#checkvcf","title":"CheckVCF","text":"<p>Use checkVCF to ensure that the VCF files are valid. checkVCF proposes \"Action Items\" (e.g. upload to sftp server), which can be ignored. Only the validity should be checked with this command.</p> <pre><code>checkVCF.py -r human_g1k_v37.fasta -o out mystudy_chr1.vcf.gz\n</code></pre>"},{"location":"reference-panels/","title":"Reference Panels","text":"<p>Our server offers imputation from the following reference panels:</p>"},{"location":"reference-panels/#hrc-version-r11-2016","title":"HRC (Version r1.1 2016)","text":"<p>The HRC panel consists of 64,940 haplotypes of predominantly European ancestry.</p> Number of Samples 32,470 Sites (chr1-22) 39,635,008 Chromosomes 1-22, X Website http://www.haplotype-reference-consortium.org; HRC r1.1 Release Note"},{"location":"reference-panels/#1000-genomes-phase-3-version-5","title":"1000 Genomes Phase 3 (Version 5)","text":"<p>Phase 3 of the 1000 Genomes Project consists of 5,008 haplotypes from 26 populations across the world.</p> Number of Samples 2,504 Sites (chr1-22) 49,143,605 Chromosomes 1-22, X Website http://www.internationalgenome.org"},{"location":"reference-panels/#genome-asia-pilot-gasp","title":"Genome Asia Pilot - GAsP","text":"Number of Samples 1,654 Sites (chr1-22) 21,494,814 Chromosomes 1-22 Publication https://www.nature.com/articles/s41586-019-1793-z"},{"location":"reference-panels/#genome-asia-v2-gasp","title":"Genome Asia v2 - GAsP","text":"Number of Samples 6,461 Sites (chr1-22) - Chromosomes 1-22 Publication https://www.nature.com/articles/s41586-019-1793-z"},{"location":"reference-panels/#four-digit-multi-ethnic-hla-v1-2021","title":"Four-digit Multi-ethnic HLA v1 (2021)","text":"<p>The multi-ethnic HLA panel consists of 36,586 haplotypes of five global populations. We have released the panel at both two-field (four-digit) and G-group resolution.</p> Number of Samples 18,293 Sites (chr6) 56,310 (1,781 HLA alleles; 4,513 HLA amino acids; 10,924 SNPs within HLA; 39,092 scaffold SNPs) Chromosomes 6:28,000,000-34,000,000 Website https://github.com/immunogenomics/HLA-TAPAS/ <p>Please cite this manuscript if you would like to include imputed results from the panel in  your work:</p> <p>Luo, Y., Kanai, M., Choi, W., Li, X., Yamamoto, K., Ogawa, K., Gutierrez-Arcelus, M., Gregersen, P. K., Stuart, P. E., Elder, J. T., Fellay, J., Carrington, M., Haas, D. W., Guo, X., Palmer, N. D., Chen, Y.-D. I., Rotter, J. I., Taylor, K. D., Rich, S., \u2026 Raychaudhuri, S. (2020). A high-resolution HLA reference panel capturing global population diversity enables multi-ethnic fine-mapping in HIV host response. https://doi.org/10.1101/2020.07.16.20155606</p>"},{"location":"reference-panels/#four-digit-multi-ethnic-hla-v2-2022","title":"Four-digit Multi-ethnic HLA v2 (2022)","text":"Number of Samples 20,349 Sites (chr6) 22,733 (570 HLA alleles; 3,449 HLA amino acids; 4,023 SNPs within HLA; 14,691 scaffold SNPs) Chromosomes 6:27,970,031-33,965,553 Website https://github.com/immunogenomics/HLA-TAPAS/"},{"location":"reference-panels/#multi-ethnic-hla-v2-details","title":"Multi-ethnic HLA v2 Details","text":"<p>Samples:</p> <ul> <li>We added Japanese samples with HLA alleles called with deep target sequencing (n = 723; Hirata et al. Nat Genet. 2019).</li> <li>Add Estonian biobank samples with IRB approval (n = 2,233; Mitt et al. Eur J Hum Genet. 2017).</li> </ul> <p>HLA alleles:</p> <ul> <li>We used gold-standard HLA allele calls (instead of inferred calls from whole genome sequencing) when possible.</li> <li>We updated and recalled HLA alleles using HLA-LA (Dilthey et al. Bioinformatics. 2019) in Jackson Heart Study (n = 3,026).</li> <li>We updated and recalled HLA alleles using HLA-LA in Estonian Biobank (n = 2,233).</li> </ul> <p>Scaffold variants:</p> <ul> <li>We added population-specific SNP variants which are common in one population but rare in the other populations when they are in 1KG and pass QC, by cross-cohort SNP imputation within the reference panel.</li> <li>We removed all SNP variants that are not included in the commonly-used genotyping arrays.</li> </ul> <p>Minimac4 options:</p> <ul> <li>We optimized <code>--probThreshold</code>, <code>--diffThreshold</code>, <code>--topThreshold</code> parameters in minimac4. Optimized parameters are now used for all HLA panels.</li> </ul> <p>Imputation results:</p> <ul> <li>We output 2-digit and 4-digit-resolution HLA alleles. We do not output higher resolution HLA alleles in this version.</li> </ul>"},{"location":"reference-panels/#caapa-african-american-panel","title":"CAAPA - African American Panel","text":"<p>Whole genome sequences were available on 883 individuals from 19 case-control studies of asthma included in the Consortium on Asthma among African-ancestry Populations in the Americas (CAAPA) and were used to summarize the genomic contributions to individuals of African ancestry.</p> Number of Samples 883 Sites (chr1-22) 31,163,897 Chromosomes 1-22 Website http://www.caapa-project.org/. Further details can also be found here"},{"location":"reference-panels/#hrc-version-r1-2015","title":"HRC (Version r1 2015)","text":"<p>This HRC panel consists of 64,976 haplotypes of predominantly European ancestry.</p> Number of Samples 32,488 Sites (chr1-22) 39,741,659 Chromosomes 1-22, X Website http://www.haplotype-reference-consortium.org; HRC r1 Release Note"},{"location":"reference-panels/#1000-genomes-phase-1-version-3","title":"1000 Genomes Phase 1 (Version 3)","text":"Number of Samples 1,092 Sites (chr1-22) 28,975,367 Chromosomes 1-22, X Website http://www.internationalgenome.org"},{"location":"reference-panels/#hapmap-2","title":"HapMap 2","text":"Number of Samples 60 Sites (chr1-22) 2,542,916 Chromosomes 1-22 Website: http://www.hapmap.org"},{"location":"pgs/faq/","title":"Frequently Asked Questions","text":""},{"location":"pgs/faq/#can-i-use-the-polygenic-score-calculation-extension-without-an-email-address","title":"Can I use the Polygenic Score Calculation extension without an email address?","text":"<p>Yes, the extension can also be used with a username without an email. However, without an email, notifications are not sent, and access to genotyped data may be limited.</p>"},{"location":"pgs/faq/#extending-expiration-date-or-reset-download-counter","title":"Extending expiration date or reset download counter","text":"<p>Your data is available for 7 days. In case you need an extension, please let us know.</p>"},{"location":"pgs/faq/#how-can-i-improve-the-download-speed","title":"How can I improve the download speed?","text":"<p>aria2 tries to utilize your maximum download bandwidth. Please keep in mind to raise the k parameter significantly (-k, --min-split-size=SIZE). You will otherwise hit the Michigan Imputation Server download limit for each file (thanks to Anthony Marcketta for point this out).</p>"},{"location":"pgs/faq/#can-i-download-all-results-at-once","title":"Can I download all results at once?","text":"<p>We provide wget command for all results. Please open the results tab. The last column in each row includes direct links to all files.</p>"},{"location":"pgs/faq/#can-i-perform-pgs-calculation-locally","title":"Can I perform PGS calculation locally?","text":"<p>Imputationserveris using a standalone tool called pgs-calc. It reads the imputed dosages from VCF files and uses them to calculate scores. It supports imputed genotypes from Michigan Imputation Server or TOPMed Imputation Server out of the box and score files from PGS Catalog or PRSWeb instances. In addition, own created score files containing chromosomal positions, both alleles and the effect size can be used easily. pgs-calc uses the chromosomal positions and alleles to find the corresponding dosages in genotype files, but provides also tools to resolve rsIDs in score files using dbSNP. Therefore, it can be applied to genotype files with variants that were not annotated with rsIDs. Moreover, the standalone version provides options to improve the coverage by using the provided proxy mapping file for Europeans or a custom population specific mapping file. pgs-calc is available at https://github.com/lukfor/pgs-calc.</p>"},{"location":"pgs/getting-started/","title":"Polygenic Score Calculation","text":"<p>We provide an easy to use and user-friendly web interface to apply thousands of published polygenic risk scores to imputed genotypes in an efficient way. By extending the popular Michigan Imputation Server the module integrates it seamless into the existing imputation workflow and enables users without knowledge in that field to take advantage of this method. The graphical report includes all meta-data about the scores in a single place and helps users to understand and screen thousands of scores in an easy and intuitive way.</p> <p></p> <p>An extensive quality control pipeline is executed automatically to detect and fix possible strand-flips and to filter out missing SNPs to prevent systematic errors (e.g. lower scores for individuals with missing or wrong aligned genetic data).</p>"},{"location":"pgs/getting-started/#getting-started","title":"Getting started","text":"<p>To utilize the Polygenic Score Calculation extension on ImputationServer, you must first register for an account. An activation email will be sent to the provided address. Once your email address is verified, you can access the service at no cost.</p> <p>Please note that the extension can also be used with a username without an email. However, without an email, notifications are not sent, and access to genotyped data may be limited.</p> <p>No dataset at hand? No problem, download our example dataset to test the PGS extension: 50-samples.zip.</p> <p>When incorporating the Polygenic Score Calculation extension in your research, please cite the following papers:</p> <p>Das S, Forer L, Sch\u00f6nherr S, Sidore C, Locke AE, Kwong A, Vrieze S, Chew EY, Levy S, McGue M, Schlessinger D, Stambolian D, Loh PR, Iacono WG, Swaroop A, Scott LJ, Cucca F, Kronenberg F, Boehnke M, Abecasis GR, Fuchsberger C. Next-generation genotype imputation service and methods. Nature Genetics 48, 1284\u20131287 (2016).</p> <p>Samuel A. Lambert, Laurent Gil, Simon Jupp, Scott C. Ritchie, Yu Xu, Annalisa Buniello, Aoife McMahon, Gad Abraham, Michael Chapman, Helen Parkinson, John Danesh, Jacqueline A. L. MacArthur and Michael Inouye. The Polygenic Score Catalog as an open database for reproducibility and systematic evaluation. Nature Genetics. doi: 10.1038/s41588-021-00783-5 (2021).</p>"},{"location":"pgs/getting-started/#setting-up-your-first-polygenic-score-calculation-job","title":"Setting up your first Polygenic Score Calculation job","text":"<ol> <li>Log in with your credentials and navigate to the Run tab to initiate a new Polygenic Score Calculation job.</li> <li>Please click on \"Polygenic Score Calculation\" and the submission dialog appears.</li> <li>The submission dialog allows you to specify job properties.</li> </ol> <p>The following options are available:</p>"},{"location":"pgs/getting-started/#reference-panel","title":"Reference Panel","text":"<p>Our PGS extension offers genotype imputation from different reference panels. The most accurate and largest panel is HRC (Version r1.1 2016). Please select one that fulfills your needs and supports the population of your input data:</p> <ul> <li>HRC (Version r1.1 2016)</li> <li>1000 Genomes Phase 3 (Version 5)</li> <li>1000 Genomes Phase 1 (Version 3)</li> <li>HapMap 2</li> </ul> <p>More details about all available reference panels can be found here. If you are unsure which reference panel to use, the \"1000 Genomes Phase 3 (Version 5)\" reference panel is multi-ancestry and has high coverage with available scores. However, if your uploaded data is European only, the HRC reference panel could be the better choice, as it enables the imputation of rare European-specific variants.</p>"},{"location":"pgs/getting-started/#upload-vcf-files-from-your-computer","title":"Upload VCF files from your computer","text":"<p>When using the file upload, data is uploaded from your local file system to Michigan Imputation Server. By clicking on Select Files an open dialog appears where you can select your VCF files:</p> <p></p> <p>Multiple files can be selected using the <code>ctrl</code>, <code>cmd</code> or <code>shift</code> keys, depending on your operating system. After you have confirmed your choice, all selected files are listed in the submission dialog:</p> <p></p> <p>Please make sure that all files fulfill the requirements.</p> <p>Important</p> <p>Since version 1.7.2 URL-based uploads (sftp and http) are no longer supported. Please use direct file uploads instead.</p>"},{"location":"pgs/getting-started/#rsq-filter","title":"rsq Filter","text":"<p>The filter ensures that only variants with an imputation quality (rsq) greater than the specified value are included in the polygenic risk score calculation. Setting the value to 0 disables the filter. Default value: 0.3.</p>"},{"location":"pgs/getting-started/#build","title":"Build","text":"<p>Please select the build of your data. Currently the options hg19 and hg38 are supported. Michigan Imputation Server automatically updates the genome positions (liftOver) of your data. All reference panels are based on hg19 coordinates.</p>"},{"location":"pgs/getting-started/#scores-and-trait-category","title":"Scores and Trait Category","text":"<p>Choose the precomputed Polygenic Score repository relevant to your study from the available options. Based on the selected repository, different trait categories appear and can be selected (e.g. Cancer scores):</p> <p></p> <p>More details about all available PGS repositories can be found here.</p>"},{"location":"pgs/getting-started/#ancestry-estimation","title":"Ancestry Estimation","text":"<p>You can enable ancestry estimation by selecting a reference population used to classify your uploaded samples. Currently, we support a worldwide panel based on HGDP.</p>"},{"location":"pgs/getting-started/#start-polygenic-score-calculation","title":"Start Polygenic Score Calculation","text":"<p>After agreeing to the Terms of Service, initiate the calculation by clicking on Submit job. The system will perform Input Validation and Quality Control immediately. If your data passes these steps, the job is added to the queue for processing.</p> <p></p>"},{"location":"pgs/getting-started/#monitoring-and-retrieving-results","title":"Monitoring and Retrieving Results","text":"<ul> <li>Input Validation: Verify the validity of your uploaded files and review basic statistics.</li> </ul> <ul> <li>Quality Control: Examine the QC report and download statistics after the system filters variants based on various criteria.</li> </ul> <ul> <li>Polygenic Score Calculation: Monitor the progress of the imputation and polygenic scores calculation in real time for each chromosome.</li> </ul>"},{"location":"pgs/getting-started/#downloading-results","title":"Downloading Results","text":"<p>Upon completion, you will be notified by email if you enter your address on registration. A zip archive containing results can be downloaded directly from the server.</p> <p></p> <p>Click on the filename to download results directly via a web-browser. For command line downloads, use the share symbol to obtain private links.</p> <p>Important: All data is automatically deleted after 7 days. Download needed data within this timeframe. A reminder is sent 48 hours before data deletion.</p>"},{"location":"pgs/output-files/","title":"Output Files","text":"<p>The Polygenic Score Calculation Results CSV file provides Polygenic Score (PGS) values for different samples and associated identifiers.  Users can leverage this CSV file to analyze and compare Polygenic Score values across different samples. The data facilitates the investigation of genetic associations and their impact on specific traits or conditions.</p>"},{"location":"pgs/output-files/#csv-format","title":"CSV Format","text":"<p>The CSV file consists of a header row and data rows:</p>"},{"location":"pgs/output-files/#header-row","title":"Header Row","text":"<ul> <li>sample: Represents the identifier for each sample.</li> <li>PGS000001, PGS000002, PGS000003, ...: Columns representing different Polygenic Score values associated with the respective identifiers.</li> </ul>"},{"location":"pgs/output-files/#data-rows","title":"Data Rows","text":"<ul> <li>Each row corresponds to a sample and provides the following information:<ul> <li>sample: Identifier for the sample.</li> <li>PGS000001, PGS000002, PGS000003, ...: Polygenic Score values associated with the respective identifiers for the given sample.</li> </ul> </li> </ul>"},{"location":"pgs/output-files/#example","title":"Example","text":"<p>Here's an example row:</p> <pre><code>sample, PGS000001, PGS000002, PGS000003, ...\nsample1, -4.485780284301654, 4.119604924228042, 0.0, -4.485780284301654\n</code></pre> <ul> <li>sample1: Sample identifier.<ul> <li>-4.485780284301654: Polygenic Score value for <code>PGS000001</code>.</li> <li>4.119604924228042: Polygenic Score value for <code>PGS000002</code>.</li> <li>0.0: Polygenic Score value for <code>PGS000003</code>.</li> </ul> </li> </ul> <p>Note:</p> <ul> <li>Polygenic Score values are provided as floating-point numbers.</li> <li>The absence of values (e.g., <code>0.0</code>) indicates a lack of Polygenic Score information for a particular identifier in a given sample.</li> </ul>"},{"location":"pgs/pipeline/","title":"Pipeline","text":""},{"location":"pgs/pipeline/#ancestry-estimation","title":"Ancestry estimation","text":"<p>We use LASER to perform principal components analysis (PCA) based on the genotypes of each sample and to place them into a reference PCA space which was constructed using a set of reference individuals [14]. We built reference coordinates based on 938 samples from the Human Genome Diversity Project (HGDP) [15] and labeled them by the ancestry categories proposed by the GWASCatalog [16] which are also used in PGS Catalog. </p>"},{"location":"pgs/reference-panels/","title":"Reference Panels for PGS Calculation","text":"<p>Our server offers PGS calculation from the following reference panels:</p>"},{"location":"pgs/reference-panels/#hrc-version-r11-2016","title":"HRC (Version r1.1 2016)","text":"<p>The HRC panel consists of 64,940 haplotypes of predominantly European ancestry.</p> Number of Samples 32,470 Sites (chr1-22) 39,635,008 Chromosomes 1-22, X Website http://www.haplotype-reference-consortium.org; HRC r1.1 Release Note"},{"location":"pgs/reference-panels/#1000-genomes-phase-3-version-5","title":"1000 Genomes Phase 3 (Version 5)","text":"<p>Phase 3 of the 1000 Genomes Project consists of 5,008 haplotypes from 26 populations across the world.</p> Number of Samples 2,504 Sites (chr1-22) 49,143,605 Chromosomes 1-22, X Website http://www.internationalgenome.org"},{"location":"pgs/reference-panels/#1000-genomes-phase-1-version-3","title":"1000 Genomes Phase 1 (Version 3)","text":"Number of Samples 1,092 Sites (chr1-22) 28,975,367 Chromosomes 1-22, X Website http://www.internationalgenome.org"},{"location":"pgs/reference-panels/#hapmap-2","title":"HapMap 2","text":"Number of Samples 60 Sites (chr1-22) 2,542,916 Chromosomes 1-22 Website: http://www.hapmap.org"},{"location":"pgs/report/","title":"Interactive Report","text":"<p>The created report contains a list of all scores, where each score has a different color based on its coverage. The color green indicates that the coverage is very high and nearly all SNPs from the score were also found in the imputed dataset. The color red indicates that very few SNPs were found and the coverage is therefore low.</p> <p></p> <p>In addition, the report includes detailed metadata for each score such as the number of variants, the number of well-imputed genotypes and the population used to construct the score. A direct link to PGS Catalog, Cancer PRSWeb or ExPRSWeb is also available for further investigation (e.g. for getting information about the method that was used to construct the score). Further, the report displays the distribution of the scores of all uploaded samples and can be interactively explored. This allows users to detect samples with either a high or low risk immediately.</p> <p>Moreover, the report gives an overview of all estimated ancestries from the uploaded genotypes and compares them with the populations of the GWAS that was used to create the score.</p> <p></p> <p>If an uploaded sample with an unsupported population is detected, a warning message is provided and the sample is excluded from the summary statistics. </p>"},{"location":"pgs/scores/","title":"Scores","text":"<p>We support currently the following PGS repositories out of the box:</p>"},{"location":"pgs/scores/#pgs-catalog","title":"PGS-Catalog","text":"<p>We use PGS Catalog as the source of scores for PGS Server (version 19. Jan 2023). the PGS Catalog is an online database that collects and annotates published scores and currently provides access to over 3,900 scores encompassing more than 580 traits.</p> <p>Samuel A. Lambert, Laurent Gil, Simon Jupp, Scott C. Ritchie, Yu Xu, Annalisa Buniello, Aoife McMahon, Gad Abraham, Michael Chapman, Helen Parkinson, John Danesh, Jacqueline A. L. MacArthur and Michael Inouye. The Polygenic Score Catalog as an open database for reproducibility and systematic evaluation. Nature Genetics. doi: 10.1038/s41588-021-00783-5 (2021).</p>"},{"location":"pgs/scores/#cancer-prsweb","title":"Cancer-PRSweb","text":"<p>Collection of scores for major cancer traits.</p> <p>Fritsche LG, Patil S, Beesley LJ, VandeHaar P, Salvatore M, Ma Y, Peng RB, Taliun D, Zhou X, Mukherjee B: Cancer PRSweb: An Online Repository with Polygenic Risk Scores for Major Cancer Traits and Their Evaluation in Two Independent Biobanks. Am J Hum Genet 2020, 107(5):815-836.</p>"},{"location":"pgs/scores/#exprsweb","title":"ExPRSweb","text":"<p>Collection of scores for common health-related exposures like body mass index or alcohol consumption.</p> <p>Ma Y, Patil S, Zhou X, Mukherjee B, Fritsche LG: ExPRSweb: An online repository with polygenic risk scores for common health-related exposures. Am J Hum Genet 2022, 109(10):1742-1760.</p>"},{"location":"pgs/tutorial/","title":"Testing Imputationserver PGS: Step by Step","text":"<p>To test Imputationserver PGS, please execute the following steps:</p> <p>0. Signup and create a login:</p> <p>Imputationserver PGS requires a login to access the Polygenic Risk Score (PGS) calculation service. This login is crucial to maintain the security and privacy of any uploaded human genotype data.</p> <p>Users have the flexibility to create this login either with or without providing an email address.  Please visit the signup page and proceed to create a login.</p> <p>1. Download the Example Dataset: Start by downloading the example dataset provided for testing the PGS extension. You can obtain the dataset by clicking on the following link: 50-samples.zip.</p> <p>2. Unpack the Data: After downloading the zip file, unzip or extract its contents to a location of your choice on your computer.</p> <p>3. Access Polygenic Risk Score Application: Navigate to the \"Run\" menu and select \"Polygenic Risk Score\" from the options.</p> <p>4. Choose 1000 Genomes Phase 3 Panel: In the Polygenic Risk Score application, select the \"1000 Genomes Phase 3\" panel as the reference dataset for imputation.</p> <p>5. Specify PGS Catalog and Trait: Identify and specify the Polygenic Score (PGS) Catalog you want to use for scoring. Choose a relevant trait for the analysis, such as \"Cancer\".</p> <p>6. Optional Ancestry Estimation: Optionally, you can choose to include ancestry estimation in your analysis. This step may enhance the precision and interpreation of the results.</p> <p>7. Agree to Terms of Service: Before proceeding, make sure to read and agree to the Terms of Service provided by Imputationserver. It is essential to comply with the platform's terms and conditions.</p> <p>8. Submit the Job: After configuring all the necessary parameters, click on the \"Submit\" button to initiate the PGS calculation.</p> <p>9. Monitor Progress: Depending on the server load, the calculation may take a certain amount of time (about 30 minutes). Allow the process to complete.</p> <p>10. Download Results: Once the calculation is finished, you can view the results provided by Imputationserver PGS and download a report and all calcuated scores.</p> <p>Congratulations! You have successfully tested Imputationserver PGS using the provided example dataset and configuration settings. Now you are ready to use the service with yout own dataset!</p>"},{"location":"workshops/ASHG2020/","title":"ASHG2020","text":"<p>Workshop ASHG2020</p>"},{"location":"workshops/ASHG2020/#the-michigan-imputation-server","title":"The Michigan Imputation Server","text":"<p>Data Preparation, Genotype Imputation, and Data Analysis</p>"},{"location":"workshops/ASHG2020/#for-questions","title":"For questions:","text":"<ul> <li>Please email us: mis-ashg2020@umich.edu</li> <li>Slack channel: Slack sign-up</li> </ul>"},{"location":"workshops/ASHG2020/#workshop-facilitators","title":"Workshop facilitator(s)","text":"<ul> <li>Christian Fuchsberger, christian.fuchsberger@eurac.edu (Eurac Research)</li> <li>Lukas Forer, lukas.forer@i-med.ac.at (Medical University of Innsbruck)</li> <li>Sarah Hanks, schanks@umich.edu (University of Michigan)</li> <li>Sebastian Schoenherr, sebastian.schoenherr@i-med.ac.at (Medical University of Innsbruck)</li> <li>Albert Smith, albertvs@umich.edu (University of Michigan)</li> <li>Cassie Spracklen, cspracklen@umass.edu (University of Massachusetts-Amherst)</li> </ul>"},{"location":"workshops/ASHG2020/#workshop-description-from-the-program","title":"Workshop description (from the program)","text":"<p>Genotype imputation is a key component of modern genetic studies. This interactive workshop is intended for anyone interested in learning how to use the Michigan Imputation Server (MIS; https://imputationserver.sph.umich.edu) to impute genotypes and how to use the imputed genotypes, with a special focus on up-coming reference panels, including the multi-ancestry panel from the TOPMed program. A brief overview of imputation and the server will be followed by demonstrations and exercises, including:</p> <ol> <li>quality control and preparation of genetic data for use on the MIS with a special focus on diverse ancestries and chromosome X</li> <li>tracking runs and use of the application program interface for larger jobs</li> <li>downloading data from the MIS and preparing data for genetic analysis</li> <li>performing a GWAS using imputed data and interpreting results, taking into account imputation quality</li> </ol> <p>We encourage participants to ask specific questions about their own projects. Workshop materials, including slides and example data sets, will be made available before the workshop and will remain online at the MIS website. We expect that this workshop will enable participants to generate high-quality imputed data sets and to properly analyze them. Attendees are expected to follow materials on their personal laptops.</p>"},{"location":"workshops/ASHG2020/#intended-audience","title":"Intended Audience","text":"<p>Attendees interested in learning how to perform genotype imputation and use imputed genotypes in their research, especially trainees. Prior experience with the analysis of genome-wide association studies (GWAS) and the unix command line are recommended for the workshop.</p>"},{"location":"workshops/ASHG2022/","title":"ASHG2022","text":"<p>Workshop ASHG2022 - Genetics and Genomics Digital Forum</p>"},{"location":"workshops/ASHG2022/#the-michigan-imputation-server","title":"The Michigan Imputation Server","text":"<p>Data Preparation, Genotype Imputation, and Data Analysis</p> <p>Workshop Website</p>"},{"location":"workshops/ASHG2022/#workshop-slides","title":"Workshop Slides","text":"<p>You can download the slides of all workshop sessions here. Please also have a look at the individual sessions below for additional training material.</p>"},{"location":"workshops/ASHG2022/#workshop-facilitators","title":"Workshop Facilitator(s)","text":"<ul> <li>Christian Fuchsberger, christian.fuchsberger@eurac.edu (Eurac Research)</li> <li>Sebastian Sch\u00f6nherr, sebastian.schoenherr@i-med.ac.at (Medical University of Innsbruck)</li> <li>Lukas Forer, lukas.forer@i-med.ac.at (Medical University of Innsbruck)</li> <li>Xueling Sim, ephsx@nus.edu.sg (National University of Singapore)</li> <li>Saori Sakaue, ssakaue@broadinstitute.org (Broad Institute)</li> <li>Albert Smith, albertvs@umich.edu (University of Michigan)</li> </ul>"},{"location":"workshops/ASHG2022/#workshop-description-from-the-program","title":"Workshop Description (from the program)","text":"<p>Genotype imputation is a key component of modern genetic association studies. The Michigan Imputation Server has thus far helped &gt; 9,600 researchers from around the world to impute &gt; 95 human genomes. This interactive workshop is intended for anyone interested in learning how to impute genotypes and to use the imputed genotypes, highlighting recent reference panels, including the multi-ancestry panel from the TOPMed program and a specialized HLA panel.</p> <p>A brief overview of imputation and the server will be followed by demonstrations and exercises, including:</p> <ol> <li> <p>quality control and preparation of genetic data for use on the MIS with a special focus on diverse ancestries, chromosome X, and the HLA region;</p> </li> <li> <p>tracking runs and use of the application program interface for larger jobs;</p> </li> <li> <p>downloading data from the MIS and preparing data for genetic analysis;</p> </li> <li> <p>performing a GWAS using imputed data and interpreting results, taking into account imputation quality;</p> </li> <li> <p>using the additional features, such as the polygenic risk score calculation.</p> </li> </ol> <p>We encourage participants to ask specific questions about their own projects. Workshop materials, including slides and example data sets, will be made available before the workshop and will remain online at the MIS website. We expect that this workshop will enable participants to generate high-quality imputed data sets and to effectively analyze them.</p>"},{"location":"workshops/ASHG2023/","title":"Overview","text":"<p>Workshop ASHG2023</p>"},{"location":"workshops/ASHG2023/#welcome-to-the-michigan-imputation-server-workshop","title":"Welcome to the Michigan Imputation Server Workshop!","text":""},{"location":"workshops/ASHG2023/#workshop-title","title":"Workshop Title","text":"<p>The Michigan Imputation Server: Data Preparation, Genotype Imputation, and Data Analysis</p>"},{"location":"workshops/ASHG2023/#topic","title":"Topic","text":"<p>Statistical Genetics and Genetic Epidemiology</p>"},{"location":"workshops/ASHG2023/#target-audience","title":"Target Audience","text":"<p>Attendees interested in learning how to perform genotype imputation and use imputed genotypes in their research, especially trainees. There are no prerequisites for this workshop. Attendees are expected to follow materials on their personal laptops.</p>"},{"location":"workshops/ASHG2023/#workshop-slides","title":"Workshop Slides","text":"<p>You can download the slides of all workshop sessions here. Please also have a look at the individual sessions below for additional training material.</p>"},{"location":"workshops/ASHG2023/#links","title":"Links","text":"<ul> <li>Interactive Poll</li> <li>Workshop Website</li> </ul>"},{"location":"workshops/ASHG2023/#workshop-facilitators","title":"Workshop Facilitator(s)","text":"<ul> <li>Christian Fuchsberger, christian.fuchsberger@eurac.edu (Eurac Research)</li> <li>Sebastian Sch\u00f6nherr, sebastian.schoenherr@i-med.ac.at (Medical University of Innsbruck)</li> <li>Lukas Forer, lukas.forer@i-med.ac.at (Medical University of Innsbruck)</li> <li>Xueling Sim, ephsx@nus.edu.sg (National University of Singapore)</li> <li>Saori Sakaue, ssakaue@broadinstitute.org (Broad Institute)</li> <li>Albert Smith, albertvs@umich.edu (University of Michigan)</li> </ul>"},{"location":"workshops/ASHG2020/Session1/","title":"Session1","text":"<p>Workshop ASHG2020  &gt; Session 1: Imputation and the Server</p>"},{"location":"workshops/ASHG2020/Session1/#slides","title":"Slides","text":"<p>Download (pdf)</p>"},{"location":"workshops/ASHG2020/Session1/#links","title":"Links","text":"<p>Michigan Imputation Server</p> <p>TOPMed Imputation Server</p>"},{"location":"workshops/ASHG2020/Session1/#selected-literature","title":"Selected Literature","text":"<p>Das S, Forer L, Sch\u00f6nherr S, Sidore C, Locke AE, Kwong A, Vrieze SI, Chew EY, Levy S, McGue M, Schlessinger D, Stambolian D, Loh PR, Iacono WG, Swaroop A, Scott LJ, Cucca F, Kronenberg F, Boehnke M, Abecasis GR, Fuchsberger C. Next-generation genotype imputation service and methods. Nat Genet. 2016 Oct;48(10):1284-1287. doi: 10.1038/ng.3656.</p> <p>Das S, Abecasis GR, Browning BL. Genotype Imputation from Large Reference Panels. Annu Rev Genomics Hum Genet. 2018 Aug 31;19:73-96. doi: 10.1146/annurev-genom-083117-021602.</p> <p>Fuchsberger C, Abecasis GR, Hinds DA. minimac2: faster genotype imputation. Bioinformatics. 2015 Mar 1;31(5):782-4. doi: 10.1093/bioinformatics/btu704. Epub 2014 Oct 22. PMID: 25338720; PMCID: PMC4341061.</p> <p>Howie B, Fuchsberger C, Stephens M, Marchini J, Abecasis GR. Fast and accurate genotype imputation in genome-wide association studies through pre-phasing. Nat Genet. 2012 Jul 22;44(8):955-9. doi: 10.1038/ng.2354. PMID: 22820512; PMCID: PMC3696580.</p>"},{"location":"workshops/ASHG2020/Session2/","title":"Session2","text":"<p>Workshop ASHG2020 &gt; Session 2: Run a job, Quality Control and Data Preparation</p>"},{"location":"workshops/ASHG2020/Session2/#welcome","title":"Welcome","text":"<p>Welcome to Session 2! In this session you will learn how to submit a job on Michigan Imputation Server (MIS) and how to prepare your input data that they are passing the QC step.</p>"},{"location":"workshops/ASHG2020/Session2/#download-slides","title":"Download Slides","text":"<p>If you want to access the slides from our workshop please click here: Session 2 Slides (pdf)</p>"},{"location":"workshops/ASHG2020/Session2/#tutorial","title":"Tutorial","text":""},{"location":"workshops/ASHG2020/Session2/#getting-started-video-demo","title":"Getting Started Video Demo","text":"<p>As a quick start, the following video includes all required steps to submit and monitor a job using the graphical web interface.</p>"},{"location":"workshops/ASHG2020/Session2/#run-a-job-on-your-own","title":"Run a job on your own","text":"<p>After you registered successfully, the following URL will bring you directly to the job submission page: https://imputationserver.sph.umich.edu/index.html#!run/minimac4</p>"},{"location":"workshops/ASHG2020/Session2/#submission-page-select-parameters","title":"Submission Page - Select parameters","text":"<p>The UI includes several parameters which need to be specified. Our Getting Started guide describes all required parameters to do so.</p>"},{"location":"workshops/ASHG2020/Session2/#submission-page-upload-data","title":"Submission Page - Upload data","text":"<p>We are providing two data datasets that can be downloaded from below. In case the unphased dataset is selected, an additional phasing step using Eagle is automatically performed. For this demo, we recommend seleting the HapMap 2 panel (Input parameter 'Reference panel') to get your results as quick as possible. Please also have a look at our supported reference panels when using MIS in a production setup.</p> <p>Tip</p> <p>You can also copy/paste the URL from below and change \"File Upload\" to \"URLs (HTTP)\" load the data from a remote server (GitHub in this case).</p> <ul> <li>Phased dataset chr20 hg19</li> <li>Unphased dataset chr20 hg19</li> </ul>"},{"location":"workshops/ASHG2020/Session2/#submission-page-submit","title":"Submission Page - Submit","text":"<p>After all parameters have been selected and you click 'submit', the job will be added to our Input Validation and QC queue. Please have a look at our Data Preparation Guide to learn how to prepare your dataset using a pre-imputation tool.</p>"},{"location":"workshops/ASHG2020/Session2/#monitor-jobs-download-data","title":"Monitor Jobs, Download Data","text":"<p>If the job passes the QC step, it will be added to our long-time queue. As soon as your job is finished, you will receive an email with the password to download and encrypt your data. Also checkout our Pipeline Overview Guide to learn more about the different internal parameters. The complete source code can also be found on GitHub.</p>"},{"location":"workshops/ASHG2020/Session2/#contact","title":"Contact","text":"<p>If you have any questions please write me an email or contact me on Twitter.</p>"},{"location":"workshops/ASHG2020/Session3/","title":"Session3","text":"<p>Workshop ASHG2020 &gt; Session 3: Tracking runs and downloading data</p>"},{"location":"workshops/ASHG2020/Session3/#slides","title":"Slides","text":"<p>Learn how to monitor jobs and their progress, how to download imputation results and how to decrypt results using standard software.</p> <p>Download (pdf)</p>"},{"location":"workshops/ASHG2020/Session4/","title":"Session4","text":"<p>Workshop ASHG2020 &gt; Session 4: Performing GWAS using imputed data</p>"},{"location":"workshops/ASHG2020/Session4/#slides","title":"Slides","text":"<p>Download (pdf)</p>"},{"location":"workshops/ASHG2020/Session5/","title":"Session5","text":"<p>Workshop ASHG2020 &gt; Session 5: Imputation Bot</p>"},{"location":"workshops/ASHG2020/Session5/#slides","title":"Slides","text":"<p>Learn how to use Imputation bot to automate job submission and interactions with imputation servers.</p> <p>Download (pdf)</p>"},{"location":"workshops/ASHG2020/Session5/#tutorial","title":"Tutorial","text":""},{"location":"workshops/ASHG2020/Session5/#requirements","title":"Requirements","text":"<p>You will need the following things properly installed on your computer.</p> <ul> <li>Java 8 or higher</li> </ul>"},{"location":"workshops/ASHG2020/Session5/#download-and-install","title":"Download and Install","text":"<p>Download and install the latest version from our download page using the following commands:</p> <pre><code>curl -sL imputationbot.now.sh | bash\n</code></pre> <p>Test the installation with the following command:</p> <pre><code>imputationbot version\n</code></pre> <p>The documentation is available at http://imputationbot.readthedocs.io.</p>"},{"location":"workshops/ASHG2020/Session5/#get-your-api-token","title":"Get your API Token","text":"<p>Enable API access from your Profile page.</p> <ol> <li>Login and click on your username and then profile:</li> </ol> <p></p> <ol> <li>Click on Create API Token</li> </ol> <p></p> <ol> <li>Copy your API Token and paste it when <code>imputationbot add-instance</code> ask for it.</li> </ol> <p></p> <p>Api Tokens are valid for 30 days. You can check the status in the web interface or with <code>imputationbot instances</code></p> <p></p> <ol> <li>Next, configure imputationbot with the following command:</li> </ol> <pre><code>imputationbot add-instance\n</code></pre> <pre><code>Imputation Bot 0.8.3 \ud83e\udd16\nhttps://imputationserver.sph.umich.edu\n(c) 2019-2020 Lukas Forer, Sebastian Schoenherr and Christian Fuchsberger\nBuilt by lukas on 2020-09-01T11:31:10Z\n\nImputationserver Url [https://imputationserver.sph.umich.edu]:\nAPI Token [None]: eyJjdHkiOiJ0ZXh0XC9wbGFpbiIsImFsZyI6IkhTMjU2In0.eyJtYWlsIjoibHVrYXMuZm9yZXJAaS1tZWQuYWMuYXQiLCJleHBpcmUiOjE1NzMyMjkwNTY3NTEsIm5hbWUiOiJMdWthcyBGb3JlciIsImFwaSI6dHJ1ZSwidXNlcm5hbWUiOiJsdWtmb3IifQ.qY7iEM6ul-gJ0EuHmEUHRnoS5hZs7kD1HC95NFaxE9w\n</code></pre>"},{"location":"workshops/ASHG2020/Session5/#run-imputation","title":"Run imputation","text":"<p>You can use the <code>impute</code> command to submit a job:</p> <ul> <li>The <code>--files</code> parameter defines the location of our VCF file. If we plan to impute more than one file we can enter the path to a folder or separate multiple filenames by <code>,</code>.</li> <li>We can use the <code>--refpanel</code> parameter to specify the reference panel. For the 1000 Geneoms Phase 3 panel we use <code>1000g-phase-3-v5</code>. If we are not sure what panels are provided by the server, we can use <code>imputationbot refpanels</code> to get a list of all reference panels and their supported populations.</li> <li>For <code>--population</code> we use <code>eur</code> which stands for European</li> </ul> <p>The complete command looks like this:</p> <pre><code>imputationbot impute --files /path/to/your.vcf.gz --refpanel 1000g-phase-3-v5 --population eur\n</code></pre> <p>After submission we get the URL where we can monitor the progress of our job.</p>"},{"location":"workshops/ASHG2020/Session5/#monitor-jobs","title":"Monitor Jobs","text":"<p>However, we can also use Imputation Bot to get a list all our jobs and their status:</p> <pre><code>imputationbot jobs\n</code></pre> <p>To get more details about our job, we can use the <code>jobs</code> command followed by the job ID:</p> <pre><code>imputationbot jobs job-XXXXXXXX-XXXXXX-XXX\n</code></pre>"},{"location":"workshops/ASHG2020/Session5/#download-all-results","title":"Download all Results","text":"<p>We can use the <code>download</code> command to download all imputed genotypes and the QC report at once:</p> <pre><code>imputationbot download job-XXXXXXXX-XXXXXX-XXX\n</code></pre> <p>If the job is still running, Imputation Bot waits until the job is finished and starts automatically with the download.</p> <p>You can provide Imputation Bot the password we sent you via email and it decrypts all files for you:</p> <pre><code>imputationbot download job-XXXXXXXX-XXXXXX-XXX --password MYPASSWORD\n</code></pre>"},{"location":"workshops/ASHG2020/Session5/#documentation","title":"Documentation","text":"<p>The documentation is available at http://imputationbot.readthedocs.io.</p>"},{"location":"workshops/ASHG2020/Session5/#contact","title":"Contact","text":"<p>Feel free to contact us in case of any problems.</p>"},{"location":"workshops/ASHG2020/Session6/","title":"Session6","text":"<p>Workshop ASHG2020 &gt; Session 6: The TOPMed Imputation Server</p>"},{"location":"workshops/ASHG2020/Session6/#slides","title":"Slides","text":"<p>Download (pdf)</p>"},{"location":"workshops/ASHG2020/Session7/","title":"Session7","text":"<p>Workshop ASHG2020 &gt; Session 6: Session 7: Imputation panels</p>"},{"location":"workshops/ASHG2020/Session7/#slides","title":"Slides","text":"<p>Download (pdf)</p>"},{"location":"workshops/ASHG2022/Session1/","title":"Session1","text":"<p>Workshop ASHG2022  &gt; Session 1: Imputation and the Server</p>"},{"location":"workshops/ASHG2022/Session1/#slides","title":"Slides","text":"<p>Download (pdf)</p>"},{"location":"workshops/ASHG2022/Session1/#server-links","title":"Server Links","text":"<p>Michigan Imputation Server</p> <p>TOPMed Imputation Server</p>"},{"location":"workshops/ASHG2022/Session1/#selected-literature","title":"Selected Literature","text":"<p>Das S, Forer L, Sch\u00f6nherr S, Sidore C, Locke AE, Kwong A, Vrieze SI, Chew EY, Levy S, McGue M, Schlessinger D, Stambolian D, Loh PR, Iacono WG, Swaroop A, Scott LJ, Cucca F, Kronenberg F, Boehnke M, Abecasis GR, Fuchsberger C. Next-generation genotype imputation service and methods. Nat Genet. 2016 Oct;48(10):1284-1287. doi: 10.1038/ng.3656.</p> <p>Das S, Abecasis GR, Browning BL. Genotype Imputation from Large Reference Panels. Annu Rev Genomics Hum Genet. 2018 Aug 31;19:73-96. doi: 10.1146/annurev-genom-083117-021602.</p> <p>Fuchsberger C, Abecasis GR, Hinds DA. minimac2: faster genotype imputation. Bioinformatics. 2015 Mar 1;31(5):782-4. doi: 10.1093/bioinformatics/btu704. Epub 2014 Oct 22. PMID: 25338720; PMCID: PMC4341061.</p> <p>Howie B, Fuchsberger C, Stephens M, Marchini J, Abecasis GR. Fast and accurate genotype imputation in genome-wide association studies through pre-phasing. Nat Genet. 2012 Jul 22;44(8):955-9. doi: 10.1038/ng.2354. PMID: 22820512; PMCID: PMC3696580.</p>"},{"location":"workshops/ASHG2022/Session2/","title":"Session2","text":"<p>Workshop ASHG2022 &gt; Session 2: Run a job, Data Preparation and Data Download</p>"},{"location":"workshops/ASHG2022/Session2/#welcome","title":"Welcome","text":"<p>Welcome to Session 2! In this session you will learn how to submit a job on Michigan Imputation Server (MIS) and how to prepare your input data that they are passing the QC step.</p>"},{"location":"workshops/ASHG2022/Session2/#download-slides","title":"Download Slides","text":"<p>Download (pdf)</p>"},{"location":"workshops/ASHG2022/Session2/#tutorial","title":"Tutorial","text":""},{"location":"workshops/ASHG2022/Session2/#getting-started","title":"Getting Started","text":"<p>As a quick start, the following video includes all required steps to submit and monitor a job using the graphical web interface.</p>"},{"location":"workshops/ASHG2022/Session2/#run-a-job-on-your-own","title":"Run a job on your own","text":"<p>After you registered successfully, the following URL will bring you directly to the job submission page: https://imputationserver.sph.umich.edu/index.html#!run/minimac4</p>"},{"location":"workshops/ASHG2022/Session2/#submission-page-select-parameters","title":"Submission Page - Select parameters","text":"<p>The UI includes several parameters which need to be specified. Our Getting Started guide describes all required parameters to do so.</p>"},{"location":"workshops/ASHG2022/Session2/#submission-page-upload-data","title":"Submission Page - Upload data","text":"<p>We are providing two data datasets that can be downloaded from below. In case the unphased dataset is selected, an additional phasing step using Eagle is automatically performed. For this demo, we recommend selecting the HapMap 2 panel (Input parameter 'Reference panel') to get your results as quick as possible. Please also have a look at our supported reference panels when using MIS in a production setup.</p> <p>Tip</p> <p>You can also copy/paste the URL from below and change \"File Upload\" to \"URLs (HTTP)\" load the data from a remote server (GitHub in this case).</p> <ul> <li>Phased dataset chr20 hg19</li> <li>Unphased dataset chr20 hg19</li> </ul>"},{"location":"workshops/ASHG2022/Session2/#submission-page-submit","title":"Submission Page - Submit","text":"<p>After all parameters have been selected and you click 'submit', the job will be added to our Input Validation and QC queue. Please have a look at our Data Preparation Guide to learn how to prepare your dataset using a pre-imputation tool.</p>"},{"location":"workshops/ASHG2022/Session2/#monitor-jobs-download-data","title":"Monitor Jobs, Download Data","text":"<p>If the job passes the QC step, it will be added to our long-time queue. As soon as your job is finished, you will receive an email with the password to download and encrypt your data. Also checkout our Pipeline Overview Guide to learn more about the different internal parameters. The complete source code can also be found on GitHub.</p>"},{"location":"workshops/ASHG2022/Session2/#contact","title":"Contact","text":"<p>If you have any questions please write me an email or contact me on Twitter.</p>"},{"location":"workshops/ASHG2022/Session3/","title":"Session3","text":"<p>Workshop ASHG2022 &gt; Session 3: Performing GWAS using imputed data</p>"},{"location":"workshops/ASHG2022/Session3/#slides","title":"Slides","text":"<p>Download (pdf)</p>"},{"location":"workshops/ASHG2022/Session4/","title":"Session4","text":"<p>Workshop ASHG2022 &gt; Session 4: Imputation Bot and PGS Server</p>"},{"location":"workshops/ASHG2022/Session4/#slides","title":"Slides","text":"<p>Download (pdf)</p>"},{"location":"workshops/ASHG2022/Session4/#imputation-bot-tutorial","title":"Imputation Bot Tutorial","text":""},{"location":"workshops/ASHG2022/Session4/#requirements","title":"Requirements","text":"<p>You will need the following things properly installed on your computer.</p> <ul> <li>Java 8 or higher</li> </ul>"},{"location":"workshops/ASHG2022/Session4/#download-and-install","title":"Download and Install","text":"<p>Download and install the latest version from our download page using the following commands:</p> <pre><code>curl -sL imputationbot.now.sh | bash\n</code></pre> <p>Test the installation with the following command:</p> <pre><code>imputationbot version\n</code></pre> <p>The documentation is available at http://imputationbot.readthedocs.io.</p>"},{"location":"workshops/ASHG2022/Session4/#get-your-api-token","title":"Get your API Token","text":"<p>Enable API access from your Profile page.</p> <ol> <li>Login and click on your username and then profile:</li> </ol> <p></p> <ol> <li>Click on Create API Token</li> </ol> <p></p> <ol> <li>Copy your API Token and paste it when <code>imputationbot add-instance</code> ask for it.</li> </ol> <p></p> <p>Api Tokens are valid for 30 days. You can check the status in the web interface or with <code>imputationbot instances</code></p> <p></p> <ol> <li>Next, configure imputationbot with the following command:</li> </ol> <pre><code>imputationbot add-instance\n</code></pre> <pre><code>Imputation Bot 0.8.3 \ud83e\udd16\nhttps://imputationserver.sph.umich.edu\n(c) 2019-2020 Lukas Forer, Sebastian Schoenherr and Christian Fuchsberger\nBuilt by lukas on 2020-09-01T11:31:10Z\n\nImputationserver Url [https://imputationserver.sph.umich.edu]:\nAPI Token [None]: eyJjdHkiOiJ0ZXh0XC9wbGFpbiIsImFsZyI6IkhTMjU2In0.eyJtYWlsIjoibHVrYXMuZm9yZXJAaS1tZWQuYWMuYXQiLCJleHBpcmUiOjE1NzMyMjkwNTY3NTEsIm5hbWUiOiJMdWthcyBGb3JlciIsImFwaSI6dHJ1ZSwidXNlcm5hbWUiOiJsdWtmb3IifQ.qY7iEM6ul-gJ0EuHmEUHRnoS5hZs7kD1HC95NFaxE9w\n</code></pre>"},{"location":"workshops/ASHG2022/Session4/#run-imputation","title":"Run imputation","text":"<p>You can use the <code>impute</code> command to submit a job:</p> <ul> <li>The <code>--files</code> parameter defines the location of our VCF file. If we plan to impute more than one file we can enter the path to a folder or separate multiple filenames by <code>,</code>.</li> <li>We can use the <code>--refpanel</code> parameter to specify the reference panel. For the 1000 Geneoms Phase 3 panel we use <code>1000g-phase-3-v5</code>. If we are not sure what panels are provided by the server, we can use <code>imputationbot refpanels</code> to get a list of all reference panels and their supported populations.</li> <li>For <code>--population</code> we use <code>eur</code> which stands for European</li> </ul> <p>The complete command looks like this:</p> <pre><code>imputationbot impute --files /path/to/your.vcf.gz --refpanel 1000g-phase-3-v5 --population eur\n</code></pre> <p>After submission we get the URL where we can monitor the progress of our job.</p>"},{"location":"workshops/ASHG2022/Session4/#monitor-jobs","title":"Monitor Jobs","text":"<p>However, we can also use Imputation Bot to get a list all our jobs and their status:</p> <pre><code>imputationbot jobs\n</code></pre> <p>To get more details about our job, we can use the <code>jobs</code> command followed by the job ID:</p> <pre><code>imputationbot jobs job-XXXXXXXX-XXXXXX-XXX\n</code></pre>"},{"location":"workshops/ASHG2022/Session4/#download-all-results","title":"Download all Results","text":"<p>We can use the <code>download</code> command to download all imputed genotypes and the QC report at once:</p> <pre><code>imputationbot download job-XXXXXXXX-XXXXXX-XXX\n</code></pre> <p>If the job is still running, Imputation Bot waits until the job is finished and starts automatically with the download.</p> <p>You can provide Imputation Bot the password we sent you via email and it decrypts all files for you:</p> <pre><code>imputationbot download job-XXXXXXXX-XXXXXX-XXX --password MYPASSWORD\n</code></pre>"},{"location":"workshops/ASHG2022/Session4/#documentation","title":"Documentation","text":"<p>The documentation is available at http://imputationbot.readthedocs.io.</p>"},{"location":"workshops/ASHG2022/Session4/#contact","title":"Contact","text":"<p>Feel free to contact us in case of any problems.</p>"},{"location":"workshops/ASHG2022/Session5/","title":"Session5","text":"<p>Workshop ASHG2022 &gt; Session 5: HLA Imputation</p>"},{"location":"workshops/ASHG2022/Session5/#slides","title":"Slides","text":"<p>Download (pdf)</p>"},{"location":"workshops/ASHG2022/Session6/","title":"Session6","text":"<p>Workshop ASHG2022 &gt; Session 6: The TOPMed Imputation Server</p>"},{"location":"workshops/ASHG2022/Session6/#slides","title":"Slides","text":"<p>Download (pdf)</p>"},{"location":"workshops/ASHG2023/Session1/","title":"Session 1: Imputation and the Server","text":"<p>Workshop ASHG2023  &gt; Session 1: Imputation and the Server</p>"},{"location":"workshops/ASHG2023/Session1/#server-links","title":"Server Links","text":"<p>Michigan Imputation Server</p> <p>TOPMed Imputation Server</p>"},{"location":"workshops/ASHG2023/Session1/#selected-literature","title":"Selected Literature","text":"<p>Das S, Forer L, Sch\u00f6nherr S, Sidore C, Locke AE, Kwong A, Vrieze SI, Chew EY, Levy S, McGue M, Schlessinger D, Stambolian D, Loh PR, Iacono WG, Swaroop A, Scott LJ, Cucca F, Kronenberg F, Boehnke M, Abecasis GR, Fuchsberger C. Next-generation genotype imputation service and methods. Nat Genet. 2016 Oct;48(10):1284-1287. doi: 10.1038/ng.3656.</p> <p>Das S, Abecasis GR, Browning BL. Genotype Imputation from Large Reference Panels. Annu Rev Genomics Hum Genet. 2018 Aug 31;19:73-96. doi: 10.1146/annurev-genom-083117-021602.</p> <p>Fuchsberger C, Abecasis GR, Hinds DA. minimac2: faster genotype imputation. Bioinformatics. 2015 Mar 1;31(5):782-4. doi: 10.1093/bioinformatics/btu704. Epub 2014 Oct 22. PMID: 25338720; PMCID: PMC4341061.</p> <p>Howie B, Fuchsberger C, Stephens M, Marchini J, Abecasis GR. Fast and accurate genotype imputation in genome-wide association studies through pre-phasing. Nat Genet. 2012 Jul 22;44(8):955-9. doi: 10.1038/ng.2354. PMID: 22820512; PMCID: PMC3696580.</p>"},{"location":"workshops/ASHG2023/Session2/","title":"Session 2: Run a job, Data Preparation and Data Download","text":"<p>Workshop ASHG2023 &gt; Session 2: Run a job, Data Preparation and Data Download</p>"},{"location":"workshops/ASHG2023/Session2/#welcome","title":"Welcome","text":"<p>Welcome to Session 2! In this session you will learn how to submit a job on Michigan Imputation Server (MIS) and how to prepare your input data that they are passing the QC step.</p>"},{"location":"workshops/ASHG2023/Session2/#tutorial","title":"Tutorial","text":""},{"location":"workshops/ASHG2023/Session2/#getting-started","title":"Getting Started","text":"<p>As a quick start, the following video includes all required steps to submit and monitor a job using the graphical web interface.</p>"},{"location":"workshops/ASHG2023/Session2/#run-a-job-on-your-own","title":"Run a job on your own","text":"<p>After you registered successfully, the following URL will bring you directly to the job submission page: https://imputationserver.sph.umich.edu/index.html#!run/minimac4</p>"},{"location":"workshops/ASHG2023/Session2/#submission-page-select-parameters","title":"Submission Page - Select parameters","text":"<p>The UI includes several parameters which need to be specified. Our Getting Started guide describes all required parameters to do so.</p>"},{"location":"workshops/ASHG2023/Session2/#submission-page-upload-data","title":"Submission Page - Upload data","text":"<p>We are providing two data datasets that can be downloaded from below. In case the unphased dataset is selected, an additional phasing step using Eagle is automatically performed. For this demo, we recommend selecting the HapMap 2 panel (Input parameter 'Reference panel') to get your results as quick as possible. Please also have a look at our supported reference panels when using MIS in a production setup.</p> <ul> <li>Phased dataset chr20 hg19</li> <li>Unphased dataset chr20 hg19</li> </ul>"},{"location":"workshops/ASHG2023/Session2/#submission-page-submit","title":"Submission Page - Submit","text":"<p>After all parameters have been selected and you click 'submit', the job will be added to our Input Validation and QC queue. Please have a look at our Data Preparation Guide to learn how to prepare your dataset using a pre-imputation tool.</p>"},{"location":"workshops/ASHG2023/Session2/#monitor-jobs-download-data","title":"Monitor Jobs, Download Data","text":"<p>If the job passes the QC step, it will be added to our long-time queue. As soon as your job is finished, you will receive an email with the password to download and encrypt your data. Also checkout our Pipeline Overview Guide to learn more about the different internal parameters. The complete source code can also be found on GitHub.</p>"},{"location":"workshops/ASHG2023/Session2/#qc-results","title":"QC Results","text":"<p>A simple QC report including the frequency plot is available here.</p>"},{"location":"workshops/ASHG2023/Session2/#contact","title":"Contact","text":"<p>If you have any questions please write me an email or contact me on Twitter.</p>"},{"location":"workshops/ASHG2023/Session3/","title":"Session 3: Performing GWAS using imputed data","text":"<p>Workshop ASHG2023 &gt; Session 3: Performing GWAS using imputed data</p>"},{"location":"workshops/ASHG2023/Session4/","title":"Session 4: nf-gwas, Imputation Bot and PGS Server","text":"<p>Workshop ASHG2023 &gt; Session 4: nf-gwas, Imputation Bot and PGS Server</p>"},{"location":"workshops/ASHG2023/Session4/#nf-gwas-report","title":"nf-gwas Report","text":"<p>You can download a nf-gwas test report from here. Please unzip the file and open the index.html file.</p>"},{"location":"workshops/ASHG2023/Session4/#imputation-bot-tutorial","title":"Imputation Bot Tutorial","text":""},{"location":"workshops/ASHG2023/Session4/#requirements","title":"Requirements","text":"<p>You will need the following things properly installed on your computer.</p> <ul> <li>Java 8 or higher</li> </ul>"},{"location":"workshops/ASHG2023/Session4/#download-and-install","title":"Download and Install","text":"<p>Download and install the latest version from our download page using the following commands:</p> <pre><code>curl -sL imputationbot.now.sh | bash\n</code></pre> <p>Test the installation with the following command:</p> <pre><code>imputationbot version\n</code></pre> <p>The documentation is available at http://imputationbot.readthedocs.io.</p>"},{"location":"workshops/ASHG2023/Session4/#get-your-api-token","title":"Get your API Token","text":"<p>Enable API access from your Profile page.</p> <ol> <li>Login and click on your username and then profile:</li> </ol> <p></p> <ol> <li>Click on Create API Token</li> </ol> <p></p> <ol> <li>Copy your API Token and paste it when <code>imputationbot add-instance</code> ask for it.</li> </ol> <p></p> <p>Api Tokens are valid for 30 days. You can check the status in the web interface or with <code>imputationbot instances</code></p> <p></p> <ol> <li>Next, configure imputationbot with the following command:</li> </ol> <pre><code>imputationbot add-instance\n</code></pre> <pre><code>Imputation Bot 0.8.3 \ud83e\udd16\nhttps://imputationserver.sph.umich.edu\n(c) 2019-2020 Lukas Forer, Sebastian Schoenherr and Christian Fuchsberger\nBuilt by lukas on 2020-09-01T11:31:10Z\n\nImputationserver Url [https://imputationserver.sph.umich.edu]:\nAPI Token [None]: eyJjdHkiOiJ0ZXh0XC9wbGFpbiIsImFsZyI6IkhTMjU2In0.eyJtYWlsIjoibHVrYXMuZm9yZXJAaS1tZWQuYWMuYXQiLCJleHBpcmUiOjE1NzMyMjkwNTY3NTEsIm5hbWUiOiJMdWthcyBGb3JlciIsImFwaSI6dHJ1ZSwidXNlcm5hbWUiOiJsdWtmb3IifQ.qY7iEM6ul-gJ0EuHmEUHRnoS5hZs7kD1HC95NFaxE9w\n</code></pre>"},{"location":"workshops/ASHG2023/Session4/#run-imputation","title":"Run imputation","text":"<p>You can use the <code>impute</code> command to submit a job:</p> <ul> <li>The <code>--files</code> parameter defines the location of our VCF file. If we plan to impute more than one file we can enter the path to a folder or separate multiple filenames by <code>,</code>.</li> <li>We can use the <code>--refpanel</code> parameter to specify the reference panel. For the 1000 Geneoms Phase 3 panel we use <code>1000g-phase-3-v5</code>. If we are not sure what panels are provided by the server, we can use <code>imputationbot refpanels</code> to get a list of all reference panels and their supported populations.</li> <li>For <code>--population</code> we use <code>eur</code> which stands for European</li> </ul> <p>The complete command looks like this:</p> <pre><code>imputationbot impute --files /path/to/your.vcf.gz --refpanel 1000g-phase-3-v5 --population eur\n</code></pre> <p>After submission we get the URL where we can monitor the progress of our job.</p>"},{"location":"workshops/ASHG2023/Session4/#monitor-jobs","title":"Monitor Jobs","text":"<p>However, we can also use Imputation Bot to get a list all our jobs and their status:</p> <pre><code>imputationbot jobs\n</code></pre> <p>To get more details about our job, we can use the <code>jobs</code> command followed by the job ID:</p> <pre><code>imputationbot jobs job-XXXXXXXX-XXXXXX-XXX\n</code></pre>"},{"location":"workshops/ASHG2023/Session4/#download-all-results","title":"Download all Results","text":"<p>We can use the <code>download</code> command to download all imputed genotypes and the QC report at once:</p> <pre><code>imputationbot download job-XXXXXXXX-XXXXXX-XXX\n</code></pre> <p>If the job is still running, Imputation Bot waits until the job is finished and starts automatically with the download.</p> <p>You can provide Imputation Bot the password we sent you via email and it decrypts all files for you:</p> <pre><code>imputationbot download job-XXXXXXXX-XXXXXX-XXX --password MYPASSWORD\n</code></pre>"},{"location":"workshops/ASHG2023/Session4/#documentation","title":"Documentation","text":"<p>The documentation is available at http://imputationbot.readthedocs.io.</p>"},{"location":"workshops/ASHG2023/Session4/#contact","title":"Contact","text":"<p>Feel free to contact us in case of any problems.</p>"},{"location":"workshops/ASHG2023/Session5/","title":"Session 5: HLA Imputation","text":"<p>Workshop ASHG2023 &gt; Session 5: HLA Imputation</p> <ul> <li>Example output of the HLA imputation VCF</li> </ul>"},{"location":"workshops/ASHG2023/Session6/","title":"Session 6: TOPMed Imputation Server","text":"<p>Workshop ASHG2023 &gt; Session 6: The TOPMed Imputation Server</p>"}]}